---
title: "í•œëˆˆì— ë³´ëŠ” ë¨¸ì‹ ëŸ¬ë‹ Ch.2"
excerpt: "í•¸ì¦ˆì˜¨ ë¨¸ì‹ ëŸ¬ë‹ ë¦¬ë·° - í•œëˆˆì— ë³´ëŠ” ë¨¸ì‹ ëŸ¬ë‹"

toc: true
toc_sticky: true
toc_label: "??? ?? ??"

categories:
  - í•¸ì¦ˆì˜¨ë¨¸ì‹ ëŸ¬ë‹

tags:
  - í•¸ì¦ˆì˜¨ë¨¸ì‹ ëŸ¬ë‹
  - ì‚¬ì´í‚·ëŸ°

last_modified_at: 2021-07-20
---

### 2. ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ ì²˜ìŒë¶€í„° ëê¹Œì§€

1. í° ê·¸ë¦¼ì„ ë´…ë‹ˆë‹¤.
2. ë°ì´í„°ë¥¼ êµ¬í•©ë‹ˆë‹¤.
3. ë°ì´í„°ë¡œë¶€í„° í†µì°°ì„ ì–»ê¸° ìœ„í•´ íƒìƒ‰í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
4. ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
5. ëª¨ë¸ì„ ì„ íƒí•˜ê³  í›ˆë ¨ì‹œí‚µë‹ˆë‹¤.
6. ëª¨ë¸ì„ ìƒì„¸í•˜ê²Œ ì¡°ì •í•©ë‹ˆë‹¤.
7. ì†”ë£¨ì…˜ì„ ì œì‹œí•©ë‹ˆë‹¤.
8. ì‹œìŠ¤í…œì„ ë¡ ì¹­í•˜ê³  ëª¨ë‹ˆí„°ë§í•˜ê³  ìœ ì§€ ë³´ìˆ˜í•©ë‹ˆë‹¤.

### 2.2 í° ê·¸ë¦¼ ë³´ê¸°

### 2.2.1 ë¬¸ì œ ì •ì˜

Q. ìº˜ë¦¬í¬ë‹ˆì•„ ì¸êµ¬ì¡°ì‚¬ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼íƒ ê°€ê²© ëª¨ë¸ì„ ë§Œë“œëŠ” ì¼.

-	í˜„ì¬ ì†”ë£¨ì…˜ì´ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ê°€? = ì°¸ê³  ì„±ëŠ¥ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥
-	ì§€ë„ í•™ìŠµ / ë¹„ì§€ë„ í•™ìŠµ / ê°•í™” í•™ìŠµ ì¤‘ ë¬´ì—‡? (ë¶„ë¥˜ / íšŒê·€ / ë‹¤ë¥¸ ë¬´ì—‡)
    - ì§€ë„ í•™ìŠµ â€“ ë‹¤ë³€ëŸ‰ íšŒê·€
-	ë°°ì¹˜ í•™ìŠµ / ì˜¨ë¼ì¸ í•™ìŠµ
    - ë°°ì¹˜ í•™ìŠµ â€“ ì‹œìŠ¤í…œìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ë°ì´í„°ì— ì—°ì†ì ì¸ íë¦„ì´ ì—†ê³ , ë¹ ë¥´ê²Œ ë³€í•˜ëŠ” ë°ì´í„°ì— ì ì‘í•˜ì§€ ì•Šì•„ë„ ë˜ê³ , ë°ì´í„°ê°€ ë©”ëª¨ë¦¬ì— ë“¤ì–´ê°ˆ ë§Œí¼ ì¶©ë¶„íˆ ì‘ë‹¤.

*íŒŒì´í”„ë¼ì¸ì´ë€?
- ë°ì´í„° ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì—°ì†ë˜ì–´ ìˆëŠ” ê²ƒ

### 2.2.2 ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ ì„ íƒ

- íšŒê·€ ë¬¸ì œì˜ ì „í˜•ì ì¸ ì„±ëŠ¥ ì§€í‘œ : í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE)
![image.png](attachment:image.png)

- ì´ìƒì¹˜ë¡œ ë³´ì´ëŠ” êµ¬ì—­ì´ ë§ì„ ê²½ìš° : í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE)
![image.png](attachment:image.png)

### 2.2.3 ê°€ì • ê²€ì‚¬

-	ì§€ê¸ˆê¹Œì§€ ë§Œë“  ê°€ì •ì„ ë‚˜ì—´í•˜ê³  ê²€ì‚¬í•´ë³´ê¸°
    - íšŒê·€ê°€ ë§ëŠ”ì§€, ë¶„ë¥˜ê°€ ë§ëŠ”ì§€ : ë‚˜ì¤‘ì— í° ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŒ. ê°€ì¥ ì¤‘ìš”í•¨.

### 2.3 ë°ì´í„° ê°€ì ¸ì˜¤ê¸°

### 2.3.2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ


```python
import os
import tarfile
from six.moves import urllib

DOWNLOAD_ROOT = "https://raw.githubusercontent.com/ageron/handson-ml/master/"
HOUSING_PATH = "datasets/housing"
HOUSING_URL = DOWNLOAD_ROOT + HOUSING_PATH + "/housing.tgz"

def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):
    if not os.path.isdir(housing_path):
        os.makedirs(housing_path)
    tgz_path = os.path.join(housing_path, "housing.tgz")
    urllib.request.urlretrieve(housing_url, tgz_path)
    housing_tgz = tarfile.open(tgz_path)
    housing_tgz.extractall(path=housing_path)
    housing_tgz.close()
```


```python
fetch_housing_data()
```


```python
import pandas as pd

def load_housing_data(housing_path=HOUSING_PATH):
    csv_path = os.path.join(housing_path, "housing.csv")
    return pd.read_csv(csv_path)
```

### 2.3.3. ë°ì´í„° êµ¬ì¡° í›‘ì–´ë³´ê¸°


```python
housing = load_housing_data()
housing.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div>




```python
housing.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 20640 entries, 0 to 20639
    Data columns (total 10 columns):
     #   Column              Non-Null Count  Dtype  
    ---  ------              --------------  -----  
     0   longitude           20640 non-null  float64
     1   latitude            20640 non-null  float64
     2   housing_median_age  20640 non-null  float64
     3   total_rooms         20640 non-null  float64
     4   total_bedrooms      20433 non-null  float64
     5   population          20640 non-null  float64
     6   households          20640 non-null  float64
     7   median_income       20640 non-null  float64
     8   median_house_value  20640 non-null  float64
     9   ocean_proximity     20640 non-null  object 
    dtypes: float64(9), object(1)
    memory usage: 1.6+ MB



```python
housing['ocean_proximity'].value_counts()
```




    <1H OCEAN     9136
    INLAND        6551
    NEAR OCEAN    2658
    NEAR BAY      2290
    ISLAND           5
    Name: ocean_proximity, dtype: int64



ocean_proximimty ì»¬ëŸ¼ì˜ objectíŠ¹ì„±ì´ ë²”ì£¼í˜• ë³€ìˆ˜ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.


```python
housing.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20433.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-119.569704</td>
      <td>35.631861</td>
      <td>28.639486</td>
      <td>2635.763081</td>
      <td>537.870553</td>
      <td>1425.476744</td>
      <td>499.539680</td>
      <td>3.870671</td>
      <td>206855.816909</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.003532</td>
      <td>2.135952</td>
      <td>12.585558</td>
      <td>2181.615252</td>
      <td>421.385070</td>
      <td>1132.462122</td>
      <td>382.329753</td>
      <td>1.899822</td>
      <td>115395.615874</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-124.350000</td>
      <td>32.540000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>0.499900</td>
      <td>14999.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-121.800000</td>
      <td>33.930000</td>
      <td>18.000000</td>
      <td>1447.750000</td>
      <td>296.000000</td>
      <td>787.000000</td>
      <td>280.000000</td>
      <td>2.563400</td>
      <td>119600.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-118.490000</td>
      <td>34.260000</td>
      <td>29.000000</td>
      <td>2127.000000</td>
      <td>435.000000</td>
      <td>1166.000000</td>
      <td>409.000000</td>
      <td>3.534800</td>
      <td>179700.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-118.010000</td>
      <td>37.710000</td>
      <td>37.000000</td>
      <td>3148.000000</td>
      <td>647.000000</td>
      <td>1725.000000</td>
      <td>605.000000</td>
      <td>4.743250</td>
      <td>264725.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>-114.310000</td>
      <td>41.950000</td>
      <td>52.000000</td>
      <td>39320.000000</td>
      <td>6445.000000</td>
      <td>35682.000000</td>
      <td>6082.000000</td>
      <td>15.000100</td>
      <td>500001.000000</td>
    </tr>
  </tbody>
</table>
</div>



ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ë¥¼ ì‚´í´ë³´ê¸° ìœ„í•´ describe()í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì˜€ê³ , ì´ë¥¼ ë” ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´ ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ ë³¸ë‹¤.


```python
%matplotlib inline
import matplotlib.pyplot as plt
housing.hist(bins=50, figsize=(20,15))
plt.show()
```


![png](output_21_0.png)


median_incomeì˜ ê²½ìš° USë‹¬ëŸ¬ë¡œ í‘œí˜„ë˜ì–´ìˆì§€ ì•Šì€ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.
ë°ì´í„°ë¥¼ ì·¨í•©í•œ íŒ€ì—ê²Œ ë¬¸ì˜í•˜ì—¬ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ê³„ì‚°ëœê±´ì§€ íŒŒì•…í•´ì•¼ í•œë‹¤.

housing_median_ageì™€ median house valueëŠ” ìµœëŒ“ê°’ì— ëª°ë ¤ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì•„ ìµœëŒ€/ìµœì†Œë¥¼ í•œì •í–ˆì„ ìˆ˜ ìˆë‹¤.

median house valueëŠ” ë ˆì´ë¸” ê°’ì´ê¸° ë•Œë¬¸ì— ì˜ˆì¸¡ì´ ì •í™•í•˜ê²Œ ë˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤.

ë”°ë¼ì„œ, í´ë¼ì´ì–¸íŠ¸ íŒ€ê³¼ í•¨ê»˜ ê²€í† í•´ë´ì•¼ í•œë‹¤.

$500,000ë¥¼ ë„˜ì–´ê°€ë”ë¼ë„ ì •í™•í•œ ì˜ˆì¸¡ê°’ì´ í•„ìš”í•˜ë‹¤ë©´, ì„ íƒí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ë‘ ê°€ì§€ë‹¤.

1. í•œê³—ê°’ ë°–ì˜ êµ¬ì—­ì— ëŒ€í•œ ì •í™•í•œ ë ˆì´ë¸”ì„ êµ¬í•œë‹¤.
2. í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ì´ êµ¬ì—­ì„ ì œê±°í•˜ê³ , í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œë„ $500,000ê°€ ë„˜ëŠ” ê°’ì— ëŒ€í•œ ì˜ˆì¸¡ì€ í‰ê³¼ ê²°ê³¼ê°€ ë‚˜ì  ê²ƒì´ë¼ íŒë‹¨í•´ ì´ êµ¬ì—­ì„ ì œê±°í•œë‹¤.

### 2.3.4 í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë§Œë“¤ê¸°

ë°ì´í„° ìŠ¤ëˆ„í•‘ í¸í–¥ :

    í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ê²‰ìœ¼ë¡œ ë“œëŸ¬ë‚œ ì–´ë–¤ íŒ¨í„´ì— ì†ì•„ íŠ¹ì • ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì„ íƒí•˜ê²Œ ëœë‹¤.
    ì´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì¼ë°˜í™” ì˜¤ì°¨ë¥¼ ì¶”ì •í•˜ë©´ ë§¤ìš° ë‚™ê´€ì ì¸ ì¶”ì •ì´ ë˜ë©° ì‹œìŠ¤í…œì„ ë¡ ì¹­í–ˆì„ ë•Œ ê¸°ëŒ€í•œ ì„±ëŠ¥ì´ ë‚˜ì˜¤ì§€ ì•Šì„ ê²ƒì´ë‹¤.


```python
import numpy as np

def split_train_test(data, test_ratio):
    shuffled_indices = np.random.permutation(len(data))
    test_set_size = int(len(data) * test_ratio)
    test_indices = shuffled_indices[:test_set_size]
    train_indices = shuffled_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]
```


```python
train_set, test_set = split_train_test(housing, 0.2)
print(len(train_set), "train +", len(test_set), "test")
```

    16512 train + 4128 test


ìœ„ ì½”ë“œëŠ” ê³„ì†í•´ì„œ ë‹¤ë¥¸ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ ìƒì„±ëœë‹¤.

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´,

1. ì²˜ìŒ ì‹¤í–‰ì—ì„œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ì €ì¥í•˜ê³  ë‹¤ìŒ ë²ˆ ì‹¤í–‰ì—ì„œ ë¶ˆëŸ¬ë“¤ì¸ë‹¤.
2. np.random.permutation() í˜¸ì¶œ ì „ì— np.random.seed(42)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚œìˆ˜ ë°œìƒê¸°ì˜ ì´ˆê¹ƒê°’ì„ ì§€ì •í•œë‹¤.
3. ìƒ˜í”Œì˜ ì‹ë³„ìë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë³´ë‚¼ì§€ ì •í•¨(ìƒ˜í”Œì´ ê³ ìœ í•˜ê³  ë³€ê²½ ë¶ˆê°€ëŠ¥í•œ ì‹ë³„ìë¥¼ ê°€ì§€ê³  ìˆë‹¤ê³  ê°€ì •)


```python
from zlib import crc32

def test_set_check(identifier, test_ratio):
    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32

def split_train_test_by_id(data, test_ratio, id_column):
    ids = data[id_column]
    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))
    return data.loc[~in_test_set], data.loc[in_test_set]
```


```python
housing_with_id = housing.reset_index()
train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, "index")
```


```python
housing_with_id["id"] = housing["longitude"] * 1000 + housing["latitude"]
train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, "id")
```

í–‰ì˜ ì¸ë±ìŠ¤ë¥¼ ê³ ìœ  ì‹ë³„ìë¡œ ì‚¬ìš© = êµ¬ì—­ì˜ ìœ„ë„ì™€ ê²½ë„ëŠ” ë³€ê²½ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, idë¡œ í™œìš©.


```python
from sklearn.model_selection import train_test_split

train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)
```

sklearnì˜ ìì²´ í•¨ìˆ˜ë¡œ ë°ì´í„°ì…‹ì„ ì—¬ëŸ¬ ì„œë¸Œì…‹ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. (ë¬´ì‘ìœ„ ìƒ˜í”Œë§)


```python
housing["income_cat"] = np.ceil(housing["median_income"] / 1.5)
housing["income_cat"].where(housing["income_cat"] < 5, 5.0, inplace=True)
```

ì „ì²´ ëª¨ìˆ˜ë¥¼ ê³ ë¥´ê²Œ ì˜ ëŒ€í‘œí•  ìˆ˜ ìˆë„ë¡ ê³„ì¸µì  ìƒ˜í”Œë§ì„ ì§„í–‰í•œë‹¤. ì „ë¬¸ê°€ê°€ ì¤‘ê°„ ì†Œë“ì´ ì¤‘ê°„ ì£¼íƒ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•˜ë‹¤ê³  í•˜ì˜€ìœ¼ë¯€ë¡œ,
í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ ì „ì²´ ë°ì´í„°ì…‹ì— ìˆëŠ” ì—¬ëŸ¬ ì†Œë“ ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ ëŒ€í‘œí•´ì•¼í•œë‹¤. income_catíŠ¹ì„±ì„ ìƒì„±í•œë‹¤.


```python
housing["income_cat"].hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f90d7a5f610>




![png](output_37_1.png)



```python
from sklearn.model_selection import StratifiedShuffleSplit

split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(housing, housing["income_cat"]):
    strat_train_set = housing.loc[train_index]
    strat_test_set = housing.loc[test_index]
```


```python
housing["income_cat"].value_counts() / len(housing)
```




    3.0    0.350581
    2.0    0.318847
    4.0    0.176308
    5.0    0.114438
    1.0    0.039826
    Name: income_cat, dtype: float64




```python
for set_ in (strat_train_set, strat_test_set):
    set_.drop("income_cat", axis=1, inplace=True)
```

ê³„ì¸µì  ìƒ˜í”Œë§ì„ ì§„í–‰í•˜ì˜€ë‹¤ë©´, ì‚¬ìš©ëœ income_catì€ ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ, íŠ¹ì„±ì„ ì‚­ì œí•˜ì—¬ ë°ì´í„°ë¥¼ ì›ë˜ ìƒíƒœë¡œ ë˜ëŒë¦°ë‹¤.


```python
housing = strat_train_set.copy()
```

í›ˆë ¨ ì„¸íŠ¸ì— ëŒ€í•œ íƒìƒ‰ì„ í•˜ê¸°ì— ì•ì„œ, í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì†ìƒì‹œí‚¤ì§€ ì•Šê¸° ìœ„í•´ ë³µì‚¬ë³¸ì„ ë§Œë“¤ì–´ ì‚¬ìš©í•œë‹¤.

### 2.4 ë°ì´í„° ì´í•´ë¥¼ ìœ„í•œ íƒìƒ‰ê³¼ ì‹œê°í™”

### 2.4.1 ì§€ë¦¬ì  ë°ì´í„° ì‹œê°í™”


```python
housing.plot(kind="scatter", x="longitude", y="latitude")
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f90d7b6a8e0>




![png](output_45_1.png)


ì§€ë¦¬ ì •ë³´(ìœ„ë„ì™€ ê²½ë„)ë¥¼ í™œìš©í•˜ì—¬ ì‚°ì ë„ë¥¼ ë§Œë“¤ì–´ ë°ì´í„°ë¥¼ ì‹œê°í™” í•´ë³¸ë‹¤.


```python
housing.plot(kind="scatter", x="longitude", y="latitude", alpha=0.1)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f90d7706d00>




![png](output_47_1.png)



```python
housing.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4,
            s=housing["population"]/100, label="population", figsize=(10,7),
            c="median_house_value", cmap=plt.get_cmap("jet"), colorbar=True, sharex=False)

plt.legend()
```




    <matplotlib.legend.Legend at 0x7f90d77b1b50>




![png](output_48_1.png)


- ì›ì˜ ë°˜ì§€ë¦„(s) = êµ¬ì—­ì˜ ì¸êµ¬
- ìƒ‰ê¹”(c) = ê°€ê²©
- íˆ¬ëª…ë„(alpha) = ë°€ì§‘ëœ ì •ë„
- ìƒ‰ê¹” ë²”ìœ„(cmap) = íŒŒë‘(ë‚®ì€ ê°€ê²©) ~ ë¹¨ê°•(ë†’ì€ ê°€ê²©) ë²”ìœ„ jet

### 2.4.2 ìƒê´€ê´€ê³„ ì¡°ì‚¬


```python
corr_matrix = housing.corr()
```


```python
corr_matrix["median_house_value"].sort_values(ascending=False)
```




    median_house_value    1.000000
    median_income         0.687160
    total_rooms           0.135097
    housing_median_age    0.114110
    households            0.064506
    total_bedrooms        0.047689
    population           -0.026920
    longitude            -0.047432
    latitude             -0.142724
    Name: median_house_value, dtype: float64



labelê°’ì¸ median_house_valueì™€ì˜ ìƒê´€ê´€ê³„ë¥¼ ì‚´í´ë³¸ë‹¤.


```python
from pandas.plotting import scatter_matrix

attributes = ["median_house_value", "median_income", "total_rooms", "housing_median_age"]
scatter_matrix(housing[attributes], figsize=(12, 8))
```




    array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f90d786b640>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d776a0d0>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d79d3df0>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d78f8a60>],
           [<matplotlib.axes._subplots.AxesSubplot object at 0x7f90d73098e0>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d7480610>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d74803d0>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d729c640>],
           [<matplotlib.axes._subplots.AxesSubplot object at 0x7f90d7314580>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d781c130>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d76fc520>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d785f970>],
           [<matplotlib.axes._subplots.AxesSubplot object at 0x7f90d797cdc0>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d7912250>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d74b36a0>,
            <matplotlib.axes._subplots.AxesSubplot object at 0x7f90d7757af0>]],
          dtype=object)




![png](output_54_1.png)



```python
housing.plot(kind="scatter", x="median_income", y="median_house_value", alpha=0.1)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f90d7db2670>




![png](output_55_1.png)


ê°€ì¥ ìƒê´€ê´€ê³„ê°€ ë†’ì€ median_incomeì˜ ì‚°ì ë„ë¥¼ ìì„¸íˆ ë³´ë©´, 500000ê³¼ 400000ë“± ì´ìƒí•œ í˜•íƒœì˜ ë°ì´í„° ë¶„í¬ê°€ ë³´ì¸ë‹¤.

### 2.4.3 íŠ¹ì„± ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜


```python
housing["rooms_per_household"] = housing["total_rooms"]/housing["households"]
housing["bedrooms_per_room"] = housing["total_bedrooms"]/housing["total_rooms"]
housing["population_per_household"] = housing["population"]/housing["households"]
```


```python
corr_matrix = housing.corr()
corr_matrix["median_house_value"].sort_values(ascending=False)
```




    median_house_value          1.000000
    median_income               0.687160
    rooms_per_household         0.146285
    total_rooms                 0.135097
    housing_median_age          0.114110
    households                  0.064506
    total_bedrooms              0.047689
    population_per_household   -0.021985
    population                 -0.026920
    longitude                  -0.047432
    latitude                   -0.142724
    bedrooms_per_room          -0.259984
    Name: median_house_value, dtype: float64



ìƒˆë¡­ê²Œ ë§Œë“  íŠ¹ì„± ì¤‘ bedrooms_per_room íŠ¹ì„±ì€ ì¹¨ëŒ€/ë°©ì˜ ë¹„ìœ¨ì´ ë‚®ì€ ì§‘ì´ ë” ë¹„ì‹¼ ê²½í–¥ì´ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.

í•˜ì§€ë§Œ ì´ íƒìƒ‰ì€ ì™„ë²½í•˜ì§€ëŠ” ì•Šë‹¤. ì‹œì‘ì„ ì˜í•´ì„œ ë¹¨ë¦¬ í†µì°°ì„ ì–»ëŠ” ê²ƒì´ ì²˜ìŒ í”„ë¡œí† íƒ€ì…ì„ ì˜ ë§Œë“œëŠ”ë° ë„ì›€ì´ ë  ê²ƒì´ë‹¤.

ì´ëŠ” ë°˜ë³µì ì¸ ê³¼ì •ì´ë©°, í”„ë¡œí† íƒ€ì…ì„ ë§Œë“¤ê³  ì‹¤í–‰í•œ í›„ ê·¸ ê²°ê³¼ë¥¼ ë¶„ì„í•´ì„œ ë” ë§ì€ í†µì°°ì„ ì–»ê³  ë‹¤ì‹œ ì´ íƒìƒ‰ ë‹¨ê³„ë¡œ ëŒì•„ì˜¤ê²Œ ëœë‹¤. (ë°˜ë³µì )

### 2.5 ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„


```python
housing = strat_train_set.drop("median_house_value", axis=1)
housing_labels = strat_train_set["median_house_value"].copy()
```

ì˜ˆì¸¡ ë³€ìˆ˜ì™€ ë ˆì´ë¸”ì„ ë¶„ë¦¬í•œë‹¤.

### 2.5.1 ë°ì´í„° ì •ì œ

total_bedroomsíŠ¹ì„±ì˜ ê²°ì¸¡ê°’ ì²˜ë¦¬
1. í•´ë‹¹ êµ¬ì—­ì„ ì œê±°í•œë‹¤.
2. ì „ì²´ íŠ¹ì„±ì„ ì‚­ì œí•œë‹¤.
3. ì–´ë–¤ ê°’ìœ¼ë¡œ ì±„ìš´ë‹¤(0, í‰ê· , ì¤‘ê°„ê°’ ë“±)


```python
# housing.dropna(subset=["total_bedrooms"]) # ì˜µì…˜ 1
# housing.drop("total_bedrooms", axis=1) # ì˜µì…˜ 2
# median = housing["total_bedrooms"].median() # ì˜µì…˜ 3
# housing["total_bedrooms"].fillna(median, inplace=True)
```

ì˜µì…˜ 3ì„ ì„ íƒí•  ë•ŒëŠ” ì¤‘ê°„ê°’ì€ ê¼­ ì €ì¥í•´ì„œ ì ìš©í•´ì•¼ í•œë‹¤.


```python
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy="median")
```


```python
housing_num = housing.drop("ocean_proximity", axis=1)
```


```python
imputer.fit(housing_num)
```




    SimpleImputer(strategy='median')




```python
imputer.statistics_
```




    array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,
            408.    ,    3.5409])




```python
housing_num.median().values
```




    array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,
            408.    ,    3.5409])



ocean_proximity(ë²”ì£¼í˜•)ë¥¼ ì œì™¸í•œ ì»¬ëŸ¼ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ imputerê°ì²´ì˜ fit()ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ í›ˆë ¨ ë°ì´í„°ì— ì ìš©í•˜ì—¬ statistics_ ì†ì„±ì— ì €ì¥í•œë‹¤.

total_bedroomsíŠ¹ì„±ì—ë§Œ ëˆ„ë½ëœ ê°’ì´ ìˆì§€ë§Œ, ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ì—ì„œ ì–´ë–¤ ë°ì´í„°ê°€ ëˆ„ë½ë ì§€ í™•ì‹ í•  ìˆ˜ ì—†ê¸°ë•Œë¬¸ì—, ëª¨ë“  ìˆ˜ì¹˜í˜• íŠ¹ì„±ì— imputerë¥¼ ì ìš©í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•˜ë‹¤.


```python
X = imputer.transform(housing_num)
```


```python
housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=list(housing.index.values))
```


```python
housing_tr
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>17606</th>
      <td>-121.89</td>
      <td>37.29</td>
      <td>38.0</td>
      <td>1568.0</td>
      <td>351.0</td>
      <td>710.0</td>
      <td>339.0</td>
      <td>2.7042</td>
    </tr>
    <tr>
      <th>18632</th>
      <td>-121.93</td>
      <td>37.05</td>
      <td>14.0</td>
      <td>679.0</td>
      <td>108.0</td>
      <td>306.0</td>
      <td>113.0</td>
      <td>6.4214</td>
    </tr>
    <tr>
      <th>14650</th>
      <td>-117.20</td>
      <td>32.77</td>
      <td>31.0</td>
      <td>1952.0</td>
      <td>471.0</td>
      <td>936.0</td>
      <td>462.0</td>
      <td>2.8621</td>
    </tr>
    <tr>
      <th>3230</th>
      <td>-119.61</td>
      <td>36.31</td>
      <td>25.0</td>
      <td>1847.0</td>
      <td>371.0</td>
      <td>1460.0</td>
      <td>353.0</td>
      <td>1.8839</td>
    </tr>
    <tr>
      <th>3555</th>
      <td>-118.59</td>
      <td>34.23</td>
      <td>17.0</td>
      <td>6592.0</td>
      <td>1525.0</td>
      <td>4459.0</td>
      <td>1463.0</td>
      <td>3.0347</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6563</th>
      <td>-118.13</td>
      <td>34.20</td>
      <td>46.0</td>
      <td>1271.0</td>
      <td>236.0</td>
      <td>573.0</td>
      <td>210.0</td>
      <td>4.9312</td>
    </tr>
    <tr>
      <th>12053</th>
      <td>-117.56</td>
      <td>33.88</td>
      <td>40.0</td>
      <td>1196.0</td>
      <td>294.0</td>
      <td>1052.0</td>
      <td>258.0</td>
      <td>2.0682</td>
    </tr>
    <tr>
      <th>13908</th>
      <td>-116.40</td>
      <td>34.09</td>
      <td>9.0</td>
      <td>4855.0</td>
      <td>872.0</td>
      <td>2098.0</td>
      <td>765.0</td>
      <td>3.2723</td>
    </tr>
    <tr>
      <th>11159</th>
      <td>-118.01</td>
      <td>33.82</td>
      <td>31.0</td>
      <td>1960.0</td>
      <td>380.0</td>
      <td>1356.0</td>
      <td>356.0</td>
      <td>4.0625</td>
    </tr>
    <tr>
      <th>15775</th>
      <td>-122.45</td>
      <td>37.77</td>
      <td>52.0</td>
      <td>3095.0</td>
      <td>682.0</td>
      <td>1269.0</td>
      <td>639.0</td>
      <td>3.5750</td>
    </tr>
  </tbody>
</table>
<p>16512 rows Ã— 8 columns</p>
</div>



#### ì‚¬ì´í‚·ëŸ°ì˜ API

- ì¼ê´€ì„± : ëª¨ë“  ê°ì²´ê°€ ì¼ê´€ë˜ê³  ë‹¨ìˆœí•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê³µìœ 
    - ì¶”ì •ê¸° : ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì¼ë ¨ì˜ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë“¤ì„ ì¶”ì •í•˜ëŠ” ê°ì²´
        - ex) imputer - ì¶”ì • ìì²´ëŠ” fit() ë©”ì„œë“œì— ì˜í•´ ìˆ˜í–‰
    - ë³€í™˜ê¸° : ë°ì´í„°ì…‹ì„ ë³€í™˜í•˜ëŠ” ì¶”ì •ê¸°ë¥¼ ë³€í™˜ê¸°ë¼ê³  í•¨
        - ex) imputer - ë³€í™˜ì€ ë°ì´í„°ì…‹ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬ë°›ì€ transform() ë©”ì„œë“œì— ì˜í•´ ìˆ˜í–‰, ëª¨ë“  ë³€í™˜ê¸°ëŠ” fit()ê³¼ transform()ì„ ì—°ë‹¬ì•„ í˜¸ì¶œí•˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ fit_transform() ë©”ì„œë“œë„ ê°€ì§€ê³  ìˆë‹¤.
    - ì˜ˆì¸¡ê¸° : ì¼ë¶€ ì¶”ì •ê¸°ëŠ” ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ
        - ex) : LinearRegression ëª¨ë¸ì´ ì˜ˆì¸¡ê¸° - predict() ë©”ì„œë“œë¡œ ì˜ˆì¸¡ê°’ì„ ë°˜í™˜, score()ë©”ì„œë“œë¡œ í’ˆì§ˆì„ ì¸¡ì •
        
        
- ê²€ì‚¬ ê°€ëŠ¥ :
    - ëª¨ë“  ì¶”ì •ê¸°ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ê³µê°œ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì§ì ‘ ì ‘ê·¼í•  ìˆ˜ ìˆìŒ,
    - ëª¨ë“  ì¶”ì •ê¸°ì˜ í•™ìŠµëœ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë„ ì ‘ë¯¸ì‚¬ë¡œ ë°‘ì¤„ì„ ë¶™ì—¬ì„œ ê³µê°œ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì œê³µë¨
        - ex) imputer.strategy , imputer.statistics_
    
    
- í´ë˜ìŠ¤ ë‚¨ìš© ë°©ì§€ : ë°ì´í„°ì…‹ì„ ë³„ë„ì˜ í´ë˜ìŠ¤ê°€ ì•„ë‹ˆë¼ ë„˜íŒŒì´ ë°°ì—´ì´ë‚˜ ì‚¬ì´íŒŒì´ í¬ì†Œ í–‰ë ¬ë¡œ í‘œí˜„


- ì¡°í•©ì„± : ê¸°ì¡´ì˜ êµ¬ì„±ìš”ì†Œë¥¼ ìµœëŒ€í•œ ì¬ì‚¬ìš©, ì—¬ëŸ¬ ë³€í™˜ê¸°ë¥¼ ì—°ê²°í•œ ë‹¤ìŒ ë§ˆì§€ë§‰ì— ì¶”ì •ê¸° í•˜ë‚˜ë¥¼ ë°°ì¹˜í•œ Pipeline ì¶”ì •ê¸°ë¥¼ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŒ


- í•©ë¦¬ì ì¸ ê¸°ë³¸ê°’ : ì‹œìŠ¤í…œì„ ë¹ ë¥´ê²Œ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ ëŒ€ë¶€ë¶„ì˜ ë§¤ê°œë³€ìˆ˜ì— í•©ë¦¬ì ì¸ ê¸°ë³¸ê°’ì„ ì €ì¥í•´ë‘ì—ˆìŒ

### 2.5.2 í…ìŠ¤íŠ¸ì™€ ë²”ì£¼í˜• íŠ¹ì„± ë‹¤ë£¨ê¸°


```python
housing_cat = housing["ocean_proximity"]
```


```python
housing_cat.head(10)
```




    17606     <1H OCEAN
    18632     <1H OCEAN
    14650    NEAR OCEAN
    3230         INLAND
    3555      <1H OCEAN
    19480        INLAND
    8879      <1H OCEAN
    13685        INLAND
    4937      <1H OCEAN
    4861      <1H OCEAN
    Name: ocean_proximity, dtype: object




```python
housing_cat_encoded, housing_categories = housing_cat.factorize()
```


```python
housing_cat_encoded[:10]
```




    array([0, 0, 1, 2, 0, 2, 0, 2, 0, 0])




```python
housing_categories
```




    Index(['<1H OCEAN', 'NEAR OCEAN', 'INLAND', 'NEAR BAY', 'ISLAND'], dtype='object')



ëŒ€ë¶€ë¶„ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ ìˆ«ìí˜•ì„ ë‹¤ë£¨ë¯€ë¡œ ì´ ì¹´í…Œê³ ë¦¬ë¥¼ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë¡œ ë°”ê¾¸ì–´ ì¤€ë‹¤.

ì´ë¥¼ ìœ„í•´ ê° ì¹´í…Œê³ ë¦¬ë¥¼ ë‹¤ë¥¸ ì •ìˆ«ê°’ìœ¼ë¡œ ë§¤í•‘í•´ì£¼ëŠ” íŒë‹¤ìŠ¤ì˜ factorize() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œë‹¤.


```python
from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder()
housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))
housing_cat_1hot
```




    <16512x5 sparse matrix of type '<class 'numpy.float64'>'
    	with 16512 stored elements in Compressed Sparse Row format>



ìœ„ ë‹¨ìˆœ ë²”ì£¼í˜•ì˜ ìˆ«ìí™”ëŠ” ìˆ˜ì¹˜ì˜ ìˆœì„œí™” ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—,

ê°ê° ì¹´í…Œê³ ë¦¬ë¥¼ ì›-í•« ì¸ì½”ë”©ì„ ì§„í–‰í•´ì£¼ì–´ì•¼ í•œë‹¤.


```python
type(housing_cat_1hot)
```




    scipy.sparse.csr.csr_matrix




```python
housing_cat_1hot.toarray()
```




    array([[1., 0., 0., 0., 0.],
           [1., 0., 0., 0., 0.],
           [0., 1., 0., 0., 0.],
           ...,
           [0., 0., 1., 0., 0.],
           [1., 0., 0., 0., 0.],
           [0., 0., 0., 1., 0.]])



fit_transform() ë©”ì„œë“œëŠ” 2ì°¨ì› ë°°ì—´ì„ ë„£ì–´ì¤˜ì•¼í•˜ê¸° ë•Œë¬¸ì— ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜í•´ì¤€ë‹¤.


```python
import sklearn
print(sklearn.__version__)
```

    0.24.2



```python
# pip install scikit-learn==0.24.2
```

    Collecting scikit-learn==0.24.2
      Downloading scikit_learn-0.24.2-cp38-cp38-macosx_10_13_x86_64.whl (7.2 MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.2 MB 1.1 MB/s eta 0:00:01
    [?25hRequirement already satisfied: numpy>=1.13.3 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.24.2) (1.19.5)
    Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.24.2) (2.1.0)
    Requirement already satisfied: scipy>=0.19.1 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.24.2) (1.5.0)
    Requirement already satisfied: joblib>=0.11 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.24.2) (0.16.0)
    Installing collected packages: scikit-learn
      Attempting uninstall: scikit-learn
        Found existing installation: scikit-learn 0.23.1
        Uninstalling scikit-learn-0.23.1:
          Successfully uninstalled scikit-learn-0.23.1
    Successfully installed scikit-learn-0.24.2
    Note: you may need to restart the kernel to use updated packages.



```python
# from sklearn.preprocessing import CategoricalEncoder # sklearn 0.20ë²„ì „ì—ì„œë§Œ ì‚¬ìš©ê°€ëŠ¥
# cat_encoder = CategoricalEncoder()
# housing_cat_reshaped = housing_cat.values.reshape(-1, 1)
# housing_cat_1hot = cat_encoder.fit_transform(housing_cat_reshaped)
# housing_cat_1hot
```

ê°„ë‹¨í•˜ê²Œ CategoricalEncoderë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆì§€ë§Œ, sklearn version 0.20ì—ì„œ ì œê³µí•˜ë¯€ë¡œ, OneHotEncoderë¥¼ ì´ìš©í•˜ë„ë¡ í•œë‹¤.


```python
# from sklearn.preprocessing import OneHotEncoder
# cat_encoder = OneHotEncoder(categories='auto')
# housing_cat_reshaped = housing_cat.values.reshape(-1, 1)
# housing_cat_1hot = cat_encoder.fit_transform(housing_cat_reshaped)
# housing_cat_1hot
```


```python
# housing_cat_1hot.toarray()
```

### 2.5.3 ë‚˜ë§Œì˜ ë³€í™˜ê¸°

ì‚¬ì´í‚·ëŸ°ì´ ìœ ìš©í•œ ë³€í™˜ê¸°ë¥¼ ë§ì´ ì œê³µí•˜ì§€ë§Œ íŠ¹ë³„í•œ ì •ì œ ì‘ì—…ì´ë‚˜ ì–´ë–¤ íŠ¹ì„±ë“¤ì„ ì¡°í•©í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ ìœ„í•´ ìì‹ ë§Œì˜ ë³€í™˜ê¸°ë¥¼ ë§Œë“¤ì–´ì•¼í•  ë•Œê°€ ìˆë‹¤.
ë‚´ê°€ ë§Œë“  ë³€í™˜ê¸°ë¥¼ (íŒŒì´í”„ë¼ì¸ê³¼ ê°™ì€) ì‚¬ì´í‚·ëŸ°ì˜ ê¸°ëŠ¥ê³¼ ë§¤ë„ëŸ½ê²Œ ì—°ë™í•˜ê³  ì‹¶ì„ ê²ƒì´ë‹¤.
fit(), transform(), fit_transform() ë©”ì„œë“œë¥¼ êµ¬í˜„í•œ íŒŒì´ì¬ í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ë©´ ëœë‹¤.


```python
from sklearn.base import BaseEstimator, TransformerMixin

rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin):
    def __init__(self, add_bedrooms_per_room = True):
        self.add_bedrooms_per_room = add_bedrooms_per_room
    def fit(self, X, y=None):
        return self
    def transform(self, X, y=None):
        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]
        population_per_household = X[:, population_ix] / X[:, household_ix]
        if self.add_bedrooms_per_room:
            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else:
            return np.c_[X, rooms_per_household, population_per_household]
        
attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)
housing_extra_attribs = attr_adder.transform(housing.values)
```

ì´ ê²½ìš°ì—ëŠ” ë³€í™˜ê¸°ê°€ add_bedrooms_per_room í•˜ì´í¼íŒŒë¼ë¯¸í„° í•˜ë‚˜ë¥¼ ê°€ì§€ê³  ìˆê³  ê¸°ë³¸ê°’ì„ Trueë¡œ ì§€ì •í•©ë‹ˆë‹¤(í•©ë¦¬ì ì¸ ê¸°ë³¸ê°’ì„ ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤).
ì´ íŠ¹ì„±ì„ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì— ë„ì›€ì´ ë ì§€ ì•ˆ ë ì§€ ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ì‰½ê²Œ í™•ì¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ 100% í™•ì‹ ì´ ì—†ëŠ” ëª¨ë“  ë°ì´í„°
ì¤€ë¹„ ë‹¨ê³„ì— ëŒ€í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„ë¥¼ ìë™í™”í• ìˆ˜ë¡ ë” ë§ì€ ì¡°í•©ì„ ìë™ìœ¼ë¡œ ì‹œë„í•´ë³¼ ìˆ˜ ìˆê³  ìµœìƒì˜ ì¡°í•©ì„ ì°¾ì„
ê°€ëŠ¥ì„±ì„ ë§¤ìš° ë†’ì—¬ì¤ë‹ˆë‹¤(ê·¸ë¦¬ê³  ì‹œê°„ë„ ë§ì´ ì ˆì•½ë©ë‹ˆë‹¤)

### 2.5.4 íŠ¹ì„± ìŠ¤ì¼€ì¼ë§

ë°ì´í„°ì— ì ìš©í•  ê°€ì¥ ì¤‘ìš”í•œ ë³€í™˜ ì¤‘ í•˜ë‚˜ê°€ íŠ¹ì„± ìŠ¤ì¼€ì¼ë§(feature scaling)ì´ë‹¤.

ëª¨ë“  íŠ¹ì„±ì˜ ë²”ìœ„ë¥¼ ê°™ë„ë¡ ë§Œë“¤ì–´ì£¼ëŠ” ë°©ë²•ìœ¼ë¡œ min-max ìŠ¤ì¼€ì¼ë§ê³¼ í‘œì¤€í™”(standardization)ì´ ë„ë¦¬ ì‚¬ìš©ëœë‹¤.

1. min-max ìŠ¤ì¼€ì¼ë§
    - ë°ì´í„°ì—ì„œ ìµœì†Ÿê°’ì„ ëº€ í›„ ìµœëŒ“ê°’ê³¼ ìµœì†Ÿê°’ì˜ ì°¨ì´ë¡œ ë‚˜ëˆˆë‹¤.
    - 0~1 ë²”ìœ„ ì •ê·œí™”(normalization)
    - ì‚¬ì´í‚·ëŸ° MinMaxScaler ë³€í™˜ê¸°
    
2. í‘œì¤€í™”(standardization)
    - í‰ê· ì„ ëº€ í›„ í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ„ì–´ ê²°ê³¼ ë¶„í¬ì˜ ë¶„ì‚°ì´ 1ì´ ë˜ë„ë¡ í•œë‹¤.
    - ìƒí•œê³¼ í•˜í•œì´ ì—†ì–´ ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ì—ì„œëŠ” ë¬¸ì œê°€ ë  ìˆ˜ ìˆë‹¤. (ì‹ ê²½ë§ : 0~1 ê¸°ëŒ€)
    - ì´ìƒì¹˜ì— ì˜í–¥ì„ ëœ ë°›ëŠ”ë‹¤.
    - ì‚¬ì´í‚·ëŸ° StandardScaler ë³€í™˜ê¸°
    
    
í›ˆë ¨ ë°ì´í„°ì—ì„œë§Œ fit()ë©”ì„œë“œë¥¼ ì ìš©í•´ì•¼ í•˜ê³ , í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•´ transform()ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œë‹¤.

### 2.5.5 ë³€í™˜ íŒŒì´í”„ë¼ì¸

ë³€í™˜ ë‹¨ê³„ê°€ ë§ê¸° ë•Œë¬¸ì— ì •í™•í•œ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•œë‹¤.

ì‚¬ì´í‚·ëŸ°ì—ëŠ” ì—°ì†ëœ ë³€í™˜ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” Pipeline í´ë˜ìŠ¤ê°€ ìˆë‹¤.


```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="median")),
    ('attribs_adder', CombinedAttributesAdder()),
    ('std_scaler', StandardScaler()),
])
```

Pipelineì€ ì—°ì†ëœ ë‹¨ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì´ë¦„/ì¶”ì •ê¸° ìŒì˜ ëª©ë¡ìœ¼ë¡œ ì…ë ¥ì„ ë°›ëŠ”ë‹¤.

ë§ˆì§€ë§‰ ë‹¨ê³„ì—ëŠ” ë³€í™˜ê¸°ì™€ ì¶”ì •ê¸°ë¥¼ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆê³  ê·¸ ì™¸ì—ëŠ” ëª¨ë‘ ë³€í™˜ê¸°ì—¬ì•¼ í•œë‹¤.

íŒŒì´í”„ë¼ì¸ ê°ì²´ëŠ” ë§ˆì§€ë§‰ ì¶”ì •ê¸°ì™€ ë™ì¼í•œ ë©”ì„œë“œë¥¼ ì œê³µí•œë‹¤.


```python
from sklearn.base import BaseEstimator, TransformerMixin

class DataFrameSelector(BaseEstimator, TransformerMixin):
    def __init__(self, attribute_names):
        self.attribute_names = attribute_names
    def fit(self, X, y=None):
        return self
    def transform(self, X):
        return X[self.attribute_names].values
```

DataFrameSelectorëŠ” ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦¬ê³  í•„ìš”í•œ íŠ¹ì„±ë§Œì„ ì„ íƒí•˜ì—¬ ë°ì´í„°í”„ë ˆì„ì„ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë°”ê¾¸ëŠ” ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³€í™˜í•œë‹¤.

ì´ë¥¼ ì´ìš©í•´ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ ìˆ˜ì¹˜í˜•ë§Œ ë‹¤ë£¨ëŠ” íŒŒì´í”„ë¼ì¸ì„ ì†ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.


```python
num_attribs = list(housing_num)
cat_attribs = ["ocean_proximity"]

num_pipeline = Pipeline([
    ('selector', DataFrameSelector(num_attribs)),
    ('imputer', SimpleImputer(strategy='median')),
    ('attribs_adder', CombinedAttributesAdder()),
    ('std_scaler', StandardScaler()),
])

cat_pipeline = Pipeline([
    ('selector', DataFrameSelector(cat_attribs)),
#     ('cat_encoder', CategoricalEncoder(encoding="onehot-dense")),
    ('cat_encoder', OneHotEncoder(categories='auto')),
])
```

ì´ì œ ìƒì„±ëœ ë‘ íŒŒì´í”„ë¼ì¸ì„ FeatureUnionì„ í†µí•´ í•©ì³ì¤€ë‹¤.


```python
from sklearn.pipeline import FeatureUnion

full_pipeline = FeatureUnion(transformer_list=[
    ('num_pipeline', num_pipeline),
    ('cat_pipeline', cat_pipeline)
])
```


```python
housing_prepared = full_pipeline.fit_transform(housing)
```


```python
housing_prepared
```




    <16512x16 sparse matrix of type '<class 'numpy.float64'>'
    	with 198144 stored elements in Compressed Sparse Row format>




```python
housing_prepared.toarray()
```




    array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,
             0.        ,  0.        ],
           [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,
             0.        ,  0.        ],
           [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,
             0.        ,  1.        ],
           ...,
           [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,
             0.        ,  0.        ],
           [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,
             0.        ,  0.        ],
           [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,
             1.        ,  0.        ]])




```python
housing_prepared.shape
```




    (16512, 16)



### 2.6 ëª¨ë¸ ì„ íƒê³¼ í›ˆë ¨

### 2.6.1 í›ˆë ¨ ì„¸íŠ¸ì—ì„œ í›ˆë ¨í•˜ê³  í‰ê°€í•˜ê¸°


```python
from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, housing_labels)
```




    LinearRegression()




```python
some_data = housing.iloc[:5]
some_labels = housing_labels.iloc[:5]
some_data_prepared = full_pipeline.transform(some_data)
print("ì˜ˆì¸¡", lin_reg.predict(some_data_prepared))
print("ë ˆì´ë¸”", list(some_labels))
```

    ì˜ˆì¸¡ [210644.60458902 317768.8068993  210956.43338983  59218.98914406
     189747.55850938]
    ë ˆì´ë¸” [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]


ì¼ë¶€ ë°ì´í„°ì— ëŒ€í•´ íšŒê·€ë¶„ì„ì„ ì§„í–‰í•˜ê³ , ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ì¸¡ì •í–ˆë‹¤. ëª¨ë¸ì´ ê³¼ì†Œì í•©ë˜ì–´ìˆê¸° ë•Œë¬¸ì— ì •í™•í•œ ì¸¡ì •ì€ ì•„ë‹ˆë‹¤.


```python
from sklearn.metrics import mean_squared_error

housing_predictions = lin_reg.predict(housing_prepared)
lin_mse = mean_squared_error(housing_labels, housing_predictions)
lin_rmse = np.sqrt(lin_mse)
lin_rmse
```




    68628.19819848923



íšŒê·€ë¶„ì„ì„ ì§„í–‰í•˜ê³ , ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ì¸¡ì •í–ˆë‹¤. ëª¨ë¸ì´ ê³¼ì†Œì í•©ë˜ì–´ìˆê¸° ë•Œë¬¸ì— ì •í™•í•œ ì¸¡ì •ì€ ì•„ë‹ˆë‹¤.


```python
from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor()
tree_reg.fit(housing_prepared, housing_labels)
```




    DecisionTreeRegressor()




```python
housing_predictions = tree_reg.predict(housing_prepared)
tree_mse = mean_squared_error(housing_labels, housing_predictions)
tree_rmse = np.sqrt(tree_mse)
tree_rmse
```




    0.0



ìƒˆë¡œìš´ ëª¨ë¸ì— ëŒ€í•´ ë°ì´í„°ë¥¼ ì ìš©í•´ ë³´ì•˜ê³ , ì˜ˆì¸¡ì˜¤ì°¨ê°€ 0ìœ¼ë¡œ ê³¼ëŒ€ì í•©ì´ ëœ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.

### 2.6.2 êµì°¨ ê²€ì •ì„ ì‚¬ìš©í•œ í‰ê°€


```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(tree_reg, housing_prepared, housing_labels,
                        scoring="neg_mean_squared_error", cv=10)
tree_rmse_scores = np.sqrt(-scores)
```

íŠ¸ë¦¬ ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ íšŒê·€ ë¶„ì„ì„ ì§„í–‰í•˜ì˜€ë‹¤.

ì‚¬ì´í‚·ëŸ°ì˜ êµì°¨ ê²€ì¦ ê¸°ëŠ¥ì„ ì‚¬ìš©í•œë‹¤. ì‚¬ì´í‚·ëŸ°ì˜ êµì°¨ ê²€ì¦ ê¸°ëŠ¥ì€ scoring ë§¤ê°œë³€ìˆ˜ì— (ë‚®ì„ìˆ˜ë¡ ì¢‹ì€) ë¹„ìš© í•¨ìˆ˜ê°€ ì•„ë‹ˆê°€ (í´ìˆ˜ë¡ ì¢‹ì€)
íš¨ìš© í•¨ìˆ˜ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ í‰ê·  ì œê³± ì˜¤ì°¨(MSE)ì˜ ë°˜ëŒ“ê°’(ì¦‰, ìŒìˆ«ê°’)ì„ ê³„ì‚°í•˜ëŠ” neg_mean_squared_error í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
ì´ëŸ° ì´ìœ ë¡œ ì•ì„  ì½”ë“œì—ì„œ ì œê³±ê·¼ì„ ê³„ì‚°í•˜ê¸° ì „ì— -scoresë¡œ ë¶€í˜¸ë¥¼ ë°”ê¾¼ ê²ƒì…ë‹ˆë‹¤.

* íšŒê·€ ëª¨ë¸ì—ì„œ scoring ë§¤ê°œë³€ìˆ˜ì˜ ê¸°ë³¸ê°’ì€ 0~1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ëŠ” r2_scoreê°€ ì‚¬ìš©ëœë‹¤.


```python
def display_scores(scores):
    print("Scores:", scores)
    print("Mean:", scores.mean())
    print("Strandard deviation", scores.std())
    
display_scores(tree_rmse_scores)
```

    Scores: [68983.46389768 68035.03930543 72177.14656599 67982.20638533
     71392.68390392 75195.9673047  70836.33522371 71278.06391306
     76778.50437553 70678.11751523]
    Mean: 71333.75283905835
    Strandard deviation 2712.8476119444063


êµì°¨ê²€ì¦ì€ ì„±ëŠ¥ì¸¡ì •ì—ëŠ” ìœ ë¦¬í•˜ì§€ë§Œ, ë¹„ìš©ì´ ë¹„ì‹¸ì„œ ì–¸ì œë‚˜ ì“¸ ìˆ˜ ìˆëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤.


```python
lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,
                            scoring="neg_mean_squared_error", cv=10)
lin_rmse_scores = np.sqrt(-lin_scores)
display_scores(lin_rmse_scores)
```

    Scores: [66782.7384065  66960.1180739  70347.95253496 74739.57052051
     68031.13390131 71193.84184183 64969.63056998 68281.61137362
     71552.91570307 67665.10087687]
    Mean: 69052.4613802548
    Strandard deviation 2731.674007630782


ì„ í˜• íšŒê·€ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ, ê²°ì • íŠ¸ë¦¬ ëª¨ë¸ì´ ê³¼ëŒ€ì í•©ë˜ì–´ ì„±ëŠ¥ì´ ë” ë‚˜ì˜ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.


```python
from sklearn.ensemble import RandomForestRegressor
forest_reg = RandomForestRegressor()
forest_reg.fit(housing_prepared, housing_labels)
```




    RandomForestRegressor()




```python
housing_predictions = forest_reg.predict(housing_prepared)
forest_mse = mean_squared_error(housing_labels, housing_predictions)
forest_rmse = np.sqrt(forest_mse)
forest_rmse
```




    18716.857110739296




```python
forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,
                            scoring="neg_mean_squared_error", cv=10)
forest_rmse_scores = np.sqrt(-forest_scores)
display_scores(forest_rmse_scores)
```

    Scores: [49379.90309076 47649.35306478 50043.74244753 52008.87139895
     49356.55284207 52853.15731105 49011.32219583 48246.88963054
     52745.12941753 50114.13558696]
    Mean: 50140.905698600305
    Strandard deviation 1729.2532445246732


ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ì§€ë§Œ, ì„±ëŠ¥ë©´ì—ì„œëŠ” í›Œë¥­í•¨ì„ ë³´ì—¬ì¤€ë‹¤. í•˜ì§€ë§Œ í›ˆë ¨ ì„¸íŠ¸ì— ëŒ€í•œ ì ìˆ˜ê°€ ê²€ì¦ ì„¸íŠ¸ì— ëŒ€í•œ ì ìˆ˜ë³´ë‹¤ í›¨ì”¬ ë‚®ìœ¼ë¯€ë¡œ ì´ ëª¨ë¸ë„ ì—¬ì „íˆ í›ˆë ¨ ì„¸íŠ¸ì— ê³¼ëŒ€ì í•©ë˜ì–´ ìˆë‹¤. ê³¼ëŒ€ì í•©ì„ í•´ê²°í•˜ëŠ” ë°©ë²•ì€ 1. ëª¨ë¸ì„ ê°„ë‹¨íˆ í•˜ê±°ë‚˜, 2. ì œí•œì„ í•˜ê±°ë‚˜(ê·œì œ), 3. ë” ë§ì€ í›ˆë ¨ ë°ì´í„°ë¥¼ ëª¨ìœ¼ëŠ” ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ë¥¼ ë” ê¹Šì´ ë“¤ì–´ê°€ê¸° ì „ì—, ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì— ë„ˆë¬´ ë§ì€ ì‹œê°„ì„ ë“¤ì´ì§€ ì•Šìœ¼ë©´ì„œ ë‹¤ì–‘í•œ ëª¨ë¸(ë‹¤ì–‘í•œ ì»¤ë„ì˜ ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ , ì‹ ê²½ë§ ë“±)ì„ ì‹œë„í•´ë´ì•¼ í•œë‹¤. ê°€ëŠ¥ì„± ìˆëŠ” 2~5ê°œ ì •ë„ì˜ ëª¨ë¸ì„ ì„ ì •í•˜ëŠ” ê²ƒì´ ëª©ì ì´ë‹¤.


```python
# from sklearn.externals import joblib

# joblib.dump(my_model, "my_model.pkl")

# my_model_loaded = joblib.load("my_model.pkl")
```

* ì‹¤í—˜í•œ ëª¨ë¸ì„ ëª¨ë‘ ì €ì¥í•´ë‘ë©´ í•„ìš”í•  ë•Œ ì‰½ê²Œ ëª¨ë¸ì„ ë³µì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. êµì°¨ ê²€ì¦ ì ìˆ˜ì™€ ì‹¤ì œ ì˜ˆì¸¡ê°’ì€ ë¬¼ë¡  í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ í›ˆë ¨ëœ ëª¨ë¸ íŒŒë¼ë¯¸í„° ëª¨ë‘ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì—¬ëŸ¬ ëª¨ë¸ì˜ ì ìˆ˜ì™€ ëª¨ë¸ì´ ë§Œë“  ì˜¤ì°¨ë¥¼ ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì´ì¬ì˜ pickle íŒ¨í‚¤ì§€ë‚˜ (ë„˜íŒŒì´ ë°°ì—´ì„ ì €ì¥í•˜ëŠ” ë° ì•„ì£¼ íš¨ìœ¨ì ì¸) sklearn.externals.joblibì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì´í‚·ëŸ° ëª¨ë¸ì„ ê°„ë‹¨í•˜ê²Œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 2.7 ëª¨ë¸ ì„¸ë¶€ íŠœë‹

ê°€ëŠ¥ì„±ìˆëŠ” ëª¨ë¸ë“¤ì„ ì¶”ë ¸ë‹¤ê³  ê°€ì •í•˜ì.

###  2.7.1 ê·¸ë¦¬ë“œ íƒìƒ‰


```python
from sklearn.model_selection import GridSearchCV

param_grid = [
    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},
    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},
]

forest_reg = RandomForestRegressor()

grid_search = GridSearchCV(forest_reg, param_grid, cv=5,
                          scoring='neg_mean_squared_error',
                          return_train_score=True)

grid_search.fit(housing_prepared, housing_labels)
```




    GridSearchCV(cv=5, estimator=RandomForestRegressor(),
                 param_grid=[{'max_features': [2, 4, 6, 8],
                              'n_estimators': [3, 10, 30]},
                             {'bootstrap': [False], 'max_features': [2, 3, 4],
                              'n_estimators': [3, 10]}],
                 return_train_score=True, scoring='neg_mean_squared_error')



ê°€ì¥ ë‹¨ìˆœí•œ ë°©ë²•ìœ¼ë¡œ, ë§Œì¡±í•  ë§Œí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ì°¾ì„ ë•Œê¹Œì§€ ìˆ˜ë™ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ëŠ” ê²ƒì¸ë°, ì´ëŠ” ë§¤ìš° ì§€ë£¨í•œ ì‘ì—…ì´ê³  ë§ì€ ê²½ìš°ì˜
ìˆ˜ë¥¼ íƒìƒ‰í•˜ê¸°ì—ëŠ” ì‹œê°„ì´ ë¶€ì¡±í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ ë•ëŠ” ê²ƒì´ ì‚¬ì´í‚·ëŸ°ì˜ GridSearchCVì´ë‹¤.

ì²«ë²ˆì§¸ dictì— ìˆëŠ” ì¡°í•© 12ê°œ + ë‘ë²ˆì§¸ dictì— ìˆëŠ” ì¡°í•© 6ê°œë¥¼ í•©ì³ì„œ ì´ 18ì˜ ì¡°í•©ì„ íƒìƒ‰í•œí•˜ê³ , ê°ê° ë‹¤ì„¯ ë²ˆ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¨ë‹¤.
(5ê²¹ êµì°¨ê²€ì¦ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸)


```python
grid_search.best_params_
```




    {'max_features': 8, 'n_estimators': 30}



ì´ 90íšŒ í›ˆë ¨í•´ì•¼í•˜ê¸° ë•Œë¬¸ì— ì‹œê°„ì´ ê½¤ ì˜¤ë˜ê±¸ë¦°ë‹¤.

ìœ„ ê²°ê³¼ 8ê³¼ 30ì´ ë‚˜ì™”ëŠ”ë°, ì´ëŠ” íƒìƒ‰ ë²”ìœ„ì˜ ìµœëŒ“ê°’ì´ê¸° ë•Œë¬¸ì— ì ìˆ˜ê°€ ë” í–¥ìƒë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë” í° ê°’ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë´ì•¼ í•œë‹¤.


```python
grid_search.best_estimator_
```




    RandomForestRegressor(max_features=8, n_estimators=30)



ìµœì ì˜ ì¶”ì •ê¸°ì— ì§ì ‘ ì ‘ê·¼í•  ìˆ˜ë„ ìˆë‹¤.

GridSearchCVê°€ (ê¸°ë³¸ê°’ì¸) refit=Trueë¡œ ì´ˆê¸°í™”ë˜ì—ˆë‹¤ë©´ êµì°¨ ê²€ì¦ìœ¼ë¡œ ìµœì ì˜ ì¶”ì •ê¸°ë¥¼ ì°¾ì€ ë‹¤ìŒ ì „ì²´ í›ˆë ¨ ì„¸íŠ¸ë¡œ ë‹¤ì‹œ í›ˆë ¨ì‹œí‚¨ë‹¤.
ì¼ë°˜ì ìœ¼ë¡œ ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë˜ë¯€ë¡œ ì¢‹ì€ ë°©ë²•ì´ë‹¤.


```python
cvres = grid_search.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
    print(np.sqrt(-mean_score), params)
```

    63505.953131453134 {'max_features': 2, 'n_estimators': 3}
    55238.32008888662 {'max_features': 2, 'n_estimators': 10}
    52997.64528282196 {'max_features': 2, 'n_estimators': 30}
    59806.93370027508 {'max_features': 4, 'n_estimators': 3}
    53112.688114062286 {'max_features': 4, 'n_estimators': 10}
    50476.1425472497 {'max_features': 4, 'n_estimators': 30}
    58557.79289918644 {'max_features': 6, 'n_estimators': 3}
    51584.719911805856 {'max_features': 6, 'n_estimators': 10}
    50369.48637193193 {'max_features': 6, 'n_estimators': 30}
    58728.718764791396 {'max_features': 8, 'n_estimators': 3}
    52293.26725206924 {'max_features': 8, 'n_estimators': 10}
    50078.668364602476 {'max_features': 8, 'n_estimators': 30}
    63698.20206406498 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}
    54617.052928241494 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}
    61022.53229968242 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}
    52916.113212730896 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}
    58316.55371289239 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}
    51665.66073442937 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}


í‰ê°€ ì ìˆ˜ë„ í™•ì¸í•´ë³¼ ìˆ˜ ìˆë‹¤.

ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„ë¥¼ í•˜ë‚˜ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì²˜ëŸ¼ ë‹¤ë£° ìˆ˜ë„ ìˆë‹¤.
ì˜ˆë¥¼ ë“¤ë©´ ê·¸ë¦¬ë“œ íƒìƒ‰ì´ í™•ì‹¤í•˜ì§€ ì•Šì€ íŠ¹ì„±ì„ ì¶”ê°€í• ì§€ ë§ì§€ ìë™ìœ¼ë¡œ ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
(ì˜ˆë¥¼ ë“¤ì–´ CombinedAttributes ë³€í™˜ê¸°ì˜ add_bedrooms_per_room í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì„±ì„ ì¶”ê°€í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.)
ë¹„ìŠ·í•˜ê²Œ ì´ìƒì¹˜ê°€ ê°’ì´ ë¹ˆ íŠ¹ì„±ì„ ë‹¤ë£¨ê±°ë‚˜ íŠ¹ì„± ì„ íƒ ë“±ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë° ê·¸ë¦¬ë“œ íƒìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### 2.7.2 ëœë¤ íƒìƒ‰

ê·¸ë¦¬ë“œ íƒìƒ‰ë°©ë²•ì€ ë¹„êµì  ì ì€ ìˆ˜ì˜ ì¡°í•©ì„ íƒêµ¬í•  ë•Œ ê´œì°®ë‹¤. í•˜ì§€ë§Œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ì´ ì»¤ì§€ë©´ RandomizedSearchCVë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.
ëª¨ë“  ì¡°í•©ì„ ì‹œë„í•˜ëŠ” ëŒ€ì‹  ê° ë°˜ë³µë§ˆë‹¤ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì— ì„ì˜ì˜ ìˆ˜ë¥¼ ëŒ€ì…í•˜ì—¬ ì§€ì •í•œ íšŸìˆ˜ë§Œí¼ í‰ê°€í•˜ëŠ” ë°©ì‹ì´ë‹¤.

ì´ ë°©ì‹ì˜ ì£¼ìš” ì¥ì ì€ ë‹¤ìŒ ë‘ ê°€ì§€ ì´ë‹¤.
1. ëœë¤ íƒìƒ‰ì„ 1,000íšŒ ë°˜ë³µí•˜ë„ë¡ ì‹¤í–‰í•˜ë©´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë§ˆë‹¤ ê°ê¸° ë‹¤ë¥¸ 1,000ê°œì˜ ê°’ì„ íƒìƒ‰í•œë‹¤.(ê·¸ë¦¬ë“œ íƒìƒ‰ì€ ëª‡ ê°œì˜ ê°’ë§Œ íƒìƒ‰í•œë‹¤.)
2. ë‹¨ìˆœíˆ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì¡°ì ˆí•˜ëŠ” ê²ƒ ë§Œìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ì— íˆ¬ì…í•œ ì»´í“¨íŒ… ìì›ì„ ì œì–´í•  ìˆ˜ ìˆë‹¤.

### 2.7.3 ì•™ìƒë¸” ë°©ë²•

ëª¨ë¸ì„ ì„¸ë°€í•˜ê²Œ íŠœë‹í•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²•ì€ ìµœìƒì˜ ëª¨ë¸ì„ ì—°ê²°í•´ë³´ëŠ” ê²ƒì´ë‹¤. (ê²°ì • íŠ¸ë¦¬ì˜ ì•™ìƒë¸”ì¸ ëœë¤ í¬ë ˆìŠ¤íŠ¸ê°€ ê²°ì • íŠ¸ë¦¬ í•˜ë‚˜ë³´ë‹¤ ë” ì„±ëŠ¥ì´ ì¢‹ì€ ê²ƒì²˜ëŸ¼)

### 2.7.4 ìµœìƒì˜ ëª¨ë¸ê³¼ ì˜¤ì°¨ ë¶„ì„


```python
feature_importances = grid_search.best_estimator_.feature_importances_
feature_importances
```




    array([7.05078228e-02, 6.15657973e-02, 4.52529518e-02, 1.57663099e-02,
           1.48345128e-02, 1.53809851e-02, 1.43623705e-02, 3.68203743e-01,
           4.06542697e-02, 1.13338168e-01, 6.85368185e-02, 7.50527920e-03,
           1.58675504e-01, 6.50752004e-05, 2.62190701e-03, 2.72848462e-03])




```python
extra_attribs = ["rooms_per_hhold", "pop_per_hhold", "bedrooms_per_room"]
cat_one_hot_attribs = list(encoder.categories_[0])
attributes = num_attribs + extra_attribs + cat_one_hot_attribs
sorted(zip(feature_importances, attributes), reverse=True)
```




    [(0.36820374300431064, 'median_income'),
     (0.15867550449148063, 1),
     (0.11333816815979839, 'pop_per_hhold'),
     (0.07050782279253998, 'longitude'),
     (0.06853681847137962, 'bedrooms_per_room'),
     (0.061565797281500835, 'latitude'),
     (0.04525295179226727, 'housing_median_age'),
     (0.040654269659206176, 'rooms_per_hhold'),
     (0.015766309911249977, 'total_rooms'),
     (0.015380985098621328, 'population'),
     (0.014834512798307033, 'total_bedrooms'),
     (0.014362370513138729, 'households'),
     (0.007505279198704017, 0),
     (0.0027284846219040107, 4),
     (0.002621907005181797, 3),
     (6.50752004096158e-05, 2)]



ìœ„ ì½”ë“œì˜ ê²°ê³¼ê°€ ì±…ê³¼ ë‹¤ë¥´ì§€ë§Œ, ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëœ ì¤‘ìš”í•œ íŠ¹ì„±ë“¤ì„ ì œì™¸í•  ìˆ˜ ìˆë‹¤ (ì˜ˆë¥¼ ëœì–´ ocean_proximityì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë§Œ ì‹¤ì œë¡œ ìœ ìš©í•˜ë¯€ë¡œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ëŠ” ì œì™¸í•  ìˆ˜ ìˆë‹¤.([0,4,3,2])

### 2.7.5 í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì‹œìŠ¤í…œ í‰ê°€í•˜ê¸°


```python
final_model = grid_search.best_estimator_

X_test = strat_test_set.drop("median_house_value", axis=1)
y_test = strat_test_set["median_house_value"].copy()

X_test_prepared = full_pipeline.transform(X_test)

final_predictions = final_model.predict(X_test_prepared)

final_mse = mean_squared_error(y_test, final_predictions)
final_rmse = np.sqrt(final_mse)
```


```python
final_rmse
```




    47960.12448284642



ì–´ëŠ ì •ë„ ëª¨ë¸ì„ íŠœë‹í•˜ë©´ ë§ˆì¹¨ë‚´ ë§Œì¡±í•  ë§Œí•œ ëª¨ë¸ì„ ì–»ê²Œ ëœë‹¤. ì´ì œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ìµœì¢… ëª¨ë¸ì„ í‰ê°€í•œë‹¤. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì˜ˆì¸¡ ë³€ìˆ˜ì™€ ë ˆì´ë¸”ì„ ì–»ì€ í›„,
full_pipelineì„ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ ë³€í™˜í•˜ê³ (fit_transform()ì´ ì•„ë‹ˆë¼ transform()ì„ í˜¸ì¶œí•´ì•¼ í•œë‹¤),
í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ìµœì¢… ëª¨ë¸ì„ í‰ê°€í•œë‹¤.

í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ë§ì´ í–ˆë‹¤ë©´ êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•´ ì¸¡ì •í•œ ê²ƒë³´ë‹¤ ì¡°ê¸ˆ ì„±ëŠ¥ì´ ë‚®ì€ ê²ƒì´ ë³´í†µì´ë‹¤. ì´ëŠ” ê²€ì¦ëœ ì„¸íŠ¸ì—ì„œ ìµœì í™”ëœ ê²ƒì´ê¸° ë•Œë¬¸ì—
ë†’ì€ ì¼ë°˜í™”ë¥¼ ê¸°ëŒ€í•´ì„œëŠ” ì•ˆë˜ê¸° ë•Œë¬¸ì´ê³ , ë§Œì¡±í•´ì•¼ í•œë‹¤.

### 2.8 ë¡ ì¹­, ëª¨ë‹ˆí„°ë§, ê·¸ë¦¬ê³  ì‹œìŠ¤í…œ ìœ ì§€ ë³´ìˆ˜

### 2.10 ì—°ìŠµë¬¸ì œ

#### 1. ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  íšŒê·€(sklearn.svm.SVR)ë¥¼ kernel="linear"(í•˜ì´í¼íŒŒë¼ë¯¸í„° Cë¥¼ ë°”ê¿”ê°€ë©°)ë‚˜ kernel="rbf"(í•˜ì´í¼íŒŒë¼ë¯¸í„° Cì™€ gammaë¥¼ ë°”ê¿”ê°€ë©°) ë“±ì˜ ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”. ì§€ê¸ˆì€ ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ë„ˆë¬´ ì‹ ê²½ ì“°ì§€ ë§ˆì„¸ìš”. ìµœìƒì˜ SVRëª¨ë¸ì€ ë¬´ì—‡ì¸ê°€ìš”?


```python
from sklearn.svm import SVR

svm_reg = SVR
```

#### 2. GridSearchCVë¥¼ RandomizedSearchCVë¡œ ë°”ê¿”ë³´ì„¸ìš”.

#### 3. ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±ì„ ì„ íƒí•˜ëŠ” ë³€í™˜ê¸°ë¥¼ ì¤€ë¹„ íŒŒì´í”„ë¼ì¸ì— ì¶”ê°€í•´ë³´ì„¸ìš”.

#### 4. ì „ì²´ ë°ì´í„° ì¤€ë¹„ ê³¼ì •ê³¼ ìµœì¢… ì˜ˆì¸¡ì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë§Œë“¤ì–´ë³´ì„¸ìš”.

#### 5. GridSearchCVë¥¼ ì‚¬ìš©í•´ ì¤€ë¹„ ë‹¨ê³„ì˜ ì˜µì…˜ì„ ìë™ìœ¼ë¡œ íƒìƒ‰í•´ë³´ì„¸ìš”.


```python

```
