---
title: "한눈에 보는 머신러닝 Ch.1"
excerpt: "핸즈온 머신러닝 리뷰 - 한눈에 보는 머신러닝"

toc: true
toc_sticky: true
toc_label: "페이지 주요 목차"

categories:
  - 핸즈온머신러닝

tags:
  - 핸즈온머신러닝
  - 사이킷런

last_modified_at: 2021-07-20
---


### 1. 한눈에 보는 머신러닝

### 1.1 머신러닝이란?

머신러닝은 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학이다.

### 1.2 왜 머신러닝을 사용하는가?

-	기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 – 간단하고 성능좋은 머신러닝
-	전통적인 방식으로는 해결할 수 없는 문제 – 뛰어난 머신러닝 기법
-	유동적인 환경 – 새로운 데이터에도 적용 가능
-	복잡한 문제와 대량의 데이터에서 통찰 얻기

### 1.3 머신러닝 시스템의 종류

-	지도 / 비지도 / 준지도 / 강화 학습
    - 지도 학습 : K-NN / 선형 회귀 / 로지스틱 회귀 / 서포트 벡터 머신 / 결정 트리 / 랜덤 포레스트 / 신경망
    - 비지도 학습 : 군집 (k-평균, 계층군집(HCA), 기댓값 최대화) / 시각화와 차원 축소 (주성분 분석(PCA), 커널PCA, 지역적 선형 임베딩(LLE), t-SNE) / 연관 규칙 학습 (Apriori, Eclat)
-	온라인 학습과 배치 학습
-	사례 기반 학습과 모델 기반 학습
    (데이터 분석 – 모델 선택 – 모델 훈련 – 예측)

### 1.4 머신러인의 주요 도전 과제

-	나쁜 알고리즘
    - 훈련 데이터 과대적합 – 규제(regularization) : 하이퍼파라미터
    - 훈련 데이터 과소적합 – 파라미터 강력하게 수정, 특성 엔지니어링, 모델 제약 작게 수정
-	나쁜 데이터
    - 데이터는 양이 많을수록 좋기는 하다. 하지만 대표성을 가져야 더 좋다. <br>
    샘플이 작으면 샘플링 잡음 발생, 샘플이 커도 샘플링 편향 발생 가능
    - 낮은 품질의 데이터 – 에러, 이상치, 잡음 : 정제해야 한다. (엉터리 -> 엉터리)
    - 관련 없는 특성 – feature engineering (feature selection, feature extraction)

### 1.5 테스트와 검증

-	훈련 세트 80%, 테스트 세트 20%
-	훈련 오차, 일반화 오차(generalization error = out-of-sample error)
-	검증 세트(validation set) – 홀드 아웃(holdout) – 교차 검증(cross-validaiton)


```python

```
