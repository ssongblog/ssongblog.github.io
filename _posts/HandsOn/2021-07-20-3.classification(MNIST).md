---
title: "한눈에 보는 머신러닝 Ch.3"
excerpt: "핸즈온 머신러닝 리뷰 - 한눈에 보는 머신러닝"

toc: true
toc_sticky: true
toc_label: "페이지 주요 목차"

categories:
  - 핸즈온머신러닝

tags:
  - 핸즈온머신러닝
  - 사이킷런

last_modified_at: 2021-07-20
---


### 3. 분류
### 3.1 MNIST


```python
from sklearn.datasets import fetch_openml

mnist = fetch_openml('mnist_784', version=1, cache=True)
mnist
```




    {'data':        pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \
     0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     ...       ...     ...     ...     ...     ...     ...     ...     ...     ...   
     69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     
            pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \
     0          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     1          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     2          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     3          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     4          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     ...        ...  ...       ...       ...       ...       ...       ...   
     69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     
            pixel780  pixel781  pixel782  pixel783  pixel784  
     0           0.0       0.0       0.0       0.0       0.0  
     1           0.0       0.0       0.0       0.0       0.0  
     2           0.0       0.0       0.0       0.0       0.0  
     3           0.0       0.0       0.0       0.0       0.0  
     4           0.0       0.0       0.0       0.0       0.0  
     ...         ...       ...       ...       ...       ...  
     69995       0.0       0.0       0.0       0.0       0.0  
     69996       0.0       0.0       0.0       0.0       0.0  
     69997       0.0       0.0       0.0       0.0       0.0  
     69998       0.0       0.0       0.0       0.0       0.0  
     69999       0.0       0.0       0.0       0.0       0.0  
     
     [70000 rows x 784 columns],
     'target': 0        5
     1        0
     2        4
     3        1
     4        9
             ..
     69995    2
     69996    3
     69997    4
     69998    5
     69999    6
     Name: class, Length: 70000, dtype: category
     Categories (10, object): [0, 1, 2, 3, ..., 6, 7, 8, 9],
     'frame':        pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \
     0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     ...       ...     ...     ...     ...     ...     ...     ...     ...     ...   
     69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   
     
            pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \
     0          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     1          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     2          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     3          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     4          0.0  ...       0.0       0.0       0.0       0.0       0.0   
     ...        ...  ...       ...       ...       ...       ...       ...   
     69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   
     
            pixel781  pixel782  pixel783  pixel784  class  
     0           0.0       0.0       0.0       0.0      5  
     1           0.0       0.0       0.0       0.0      0  
     2           0.0       0.0       0.0       0.0      4  
     3           0.0       0.0       0.0       0.0      1  
     4           0.0       0.0       0.0       0.0      9  
     ...         ...       ...       ...       ...    ...  
     69995       0.0       0.0       0.0       0.0      2  
     69996       0.0       0.0       0.0       0.0      3  
     69997       0.0       0.0       0.0       0.0      4  
     69998       0.0       0.0       0.0       0.0      5  
     69999       0.0       0.0       0.0       0.0      6  
     
     [70000 rows x 785 columns],
     'categories': None,
     'feature_names': ['pixel1',
      'pixel2',
      'pixel3',
      'pixel4',
      'pixel5',
      'pixel6',
      'pixel7',
      'pixel8',
      'pixel9',
      'pixel10',
      'pixel11',
      'pixel12',
      'pixel13',
      'pixel14',
      'pixel15',
      'pixel16',
      'pixel17',
      'pixel18',
      'pixel19',
      'pixel20',
      'pixel21',
      'pixel22',
      'pixel23',
      'pixel24',
      'pixel25',
      'pixel26',
      'pixel27',
      'pixel28',
      'pixel29',
      'pixel30',
      'pixel31',
      'pixel32',
      'pixel33',
      'pixel34',
      'pixel35',
      'pixel36',
      'pixel37',
      'pixel38',
      'pixel39',
      'pixel40',
      'pixel41',
      'pixel42',
      'pixel43',
      'pixel44',
      'pixel45',
      'pixel46',
      'pixel47',
      'pixel48',
      'pixel49',
      'pixel50',
      'pixel51',
      'pixel52',
      'pixel53',
      'pixel54',
      'pixel55',
      'pixel56',
      'pixel57',
      'pixel58',
      'pixel59',
      'pixel60',
      'pixel61',
      'pixel62',
      'pixel63',
      'pixel64',
      'pixel65',
      'pixel66',
      'pixel67',
      'pixel68',
      'pixel69',
      'pixel70',
      'pixel71',
      'pixel72',
      'pixel73',
      'pixel74',
      'pixel75',
      'pixel76',
      'pixel77',
      'pixel78',
      'pixel79',
      'pixel80',
      'pixel81',
      'pixel82',
      'pixel83',
      'pixel84',
      'pixel85',
      'pixel86',
      'pixel87',
      'pixel88',
      'pixel89',
      'pixel90',
      'pixel91',
      'pixel92',
      'pixel93',
      'pixel94',
      'pixel95',
      'pixel96',
      'pixel97',
      'pixel98',
      'pixel99',
      'pixel100',
      'pixel101',
      'pixel102',
      'pixel103',
      'pixel104',
      'pixel105',
      'pixel106',
      'pixel107',
      'pixel108',
      'pixel109',
      'pixel110',
      'pixel111',
      'pixel112',
      'pixel113',
      'pixel114',
      'pixel115',
      'pixel116',
      'pixel117',
      'pixel118',
      'pixel119',
      'pixel120',
      'pixel121',
      'pixel122',
      'pixel123',
      'pixel124',
      'pixel125',
      'pixel126',
      'pixel127',
      'pixel128',
      'pixel129',
      'pixel130',
      'pixel131',
      'pixel132',
      'pixel133',
      'pixel134',
      'pixel135',
      'pixel136',
      'pixel137',
      'pixel138',
      'pixel139',
      'pixel140',
      'pixel141',
      'pixel142',
      'pixel143',
      'pixel144',
      'pixel145',
      'pixel146',
      'pixel147',
      'pixel148',
      'pixel149',
      'pixel150',
      'pixel151',
      'pixel152',
      'pixel153',
      'pixel154',
      'pixel155',
      'pixel156',
      'pixel157',
      'pixel158',
      'pixel159',
      'pixel160',
      'pixel161',
      'pixel162',
      'pixel163',
      'pixel164',
      'pixel165',
      'pixel166',
      'pixel167',
      'pixel168',
      'pixel169',
      'pixel170',
      'pixel171',
      'pixel172',
      'pixel173',
      'pixel174',
      'pixel175',
      'pixel176',
      'pixel177',
      'pixel178',
      'pixel179',
      'pixel180',
      'pixel181',
      'pixel182',
      'pixel183',
      'pixel184',
      'pixel185',
      'pixel186',
      'pixel187',
      'pixel188',
      'pixel189',
      'pixel190',
      'pixel191',
      'pixel192',
      'pixel193',
      'pixel194',
      'pixel195',
      'pixel196',
      'pixel197',
      'pixel198',
      'pixel199',
      'pixel200',
      'pixel201',
      'pixel202',
      'pixel203',
      'pixel204',
      'pixel205',
      'pixel206',
      'pixel207',
      'pixel208',
      'pixel209',
      'pixel210',
      'pixel211',
      'pixel212',
      'pixel213',
      'pixel214',
      'pixel215',
      'pixel216',
      'pixel217',
      'pixel218',
      'pixel219',
      'pixel220',
      'pixel221',
      'pixel222',
      'pixel223',
      'pixel224',
      'pixel225',
      'pixel226',
      'pixel227',
      'pixel228',
      'pixel229',
      'pixel230',
      'pixel231',
      'pixel232',
      'pixel233',
      'pixel234',
      'pixel235',
      'pixel236',
      'pixel237',
      'pixel238',
      'pixel239',
      'pixel240',
      'pixel241',
      'pixel242',
      'pixel243',
      'pixel244',
      'pixel245',
      'pixel246',
      'pixel247',
      'pixel248',
      'pixel249',
      'pixel250',
      'pixel251',
      'pixel252',
      'pixel253',
      'pixel254',
      'pixel255',
      'pixel256',
      'pixel257',
      'pixel258',
      'pixel259',
      'pixel260',
      'pixel261',
      'pixel262',
      'pixel263',
      'pixel264',
      'pixel265',
      'pixel266',
      'pixel267',
      'pixel268',
      'pixel269',
      'pixel270',
      'pixel271',
      'pixel272',
      'pixel273',
      'pixel274',
      'pixel275',
      'pixel276',
      'pixel277',
      'pixel278',
      'pixel279',
      'pixel280',
      'pixel281',
      'pixel282',
      'pixel283',
      'pixel284',
      'pixel285',
      'pixel286',
      'pixel287',
      'pixel288',
      'pixel289',
      'pixel290',
      'pixel291',
      'pixel292',
      'pixel293',
      'pixel294',
      'pixel295',
      'pixel296',
      'pixel297',
      'pixel298',
      'pixel299',
      'pixel300',
      'pixel301',
      'pixel302',
      'pixel303',
      'pixel304',
      'pixel305',
      'pixel306',
      'pixel307',
      'pixel308',
      'pixel309',
      'pixel310',
      'pixel311',
      'pixel312',
      'pixel313',
      'pixel314',
      'pixel315',
      'pixel316',
      'pixel317',
      'pixel318',
      'pixel319',
      'pixel320',
      'pixel321',
      'pixel322',
      'pixel323',
      'pixel324',
      'pixel325',
      'pixel326',
      'pixel327',
      'pixel328',
      'pixel329',
      'pixel330',
      'pixel331',
      'pixel332',
      'pixel333',
      'pixel334',
      'pixel335',
      'pixel336',
      'pixel337',
      'pixel338',
      'pixel339',
      'pixel340',
      'pixel341',
      'pixel342',
      'pixel343',
      'pixel344',
      'pixel345',
      'pixel346',
      'pixel347',
      'pixel348',
      'pixel349',
      'pixel350',
      'pixel351',
      'pixel352',
      'pixel353',
      'pixel354',
      'pixel355',
      'pixel356',
      'pixel357',
      'pixel358',
      'pixel359',
      'pixel360',
      'pixel361',
      'pixel362',
      'pixel363',
      'pixel364',
      'pixel365',
      'pixel366',
      'pixel367',
      'pixel368',
      'pixel369',
      'pixel370',
      'pixel371',
      'pixel372',
      'pixel373',
      'pixel374',
      'pixel375',
      'pixel376',
      'pixel377',
      'pixel378',
      'pixel379',
      'pixel380',
      'pixel381',
      'pixel382',
      'pixel383',
      'pixel384',
      'pixel385',
      'pixel386',
      'pixel387',
      'pixel388',
      'pixel389',
      'pixel390',
      'pixel391',
      'pixel392',
      'pixel393',
      'pixel394',
      'pixel395',
      'pixel396',
      'pixel397',
      'pixel398',
      'pixel399',
      'pixel400',
      'pixel401',
      'pixel402',
      'pixel403',
      'pixel404',
      'pixel405',
      'pixel406',
      'pixel407',
      'pixel408',
      'pixel409',
      'pixel410',
      'pixel411',
      'pixel412',
      'pixel413',
      'pixel414',
      'pixel415',
      'pixel416',
      'pixel417',
      'pixel418',
      'pixel419',
      'pixel420',
      'pixel421',
      'pixel422',
      'pixel423',
      'pixel424',
      'pixel425',
      'pixel426',
      'pixel427',
      'pixel428',
      'pixel429',
      'pixel430',
      'pixel431',
      'pixel432',
      'pixel433',
      'pixel434',
      'pixel435',
      'pixel436',
      'pixel437',
      'pixel438',
      'pixel439',
      'pixel440',
      'pixel441',
      'pixel442',
      'pixel443',
      'pixel444',
      'pixel445',
      'pixel446',
      'pixel447',
      'pixel448',
      'pixel449',
      'pixel450',
      'pixel451',
      'pixel452',
      'pixel453',
      'pixel454',
      'pixel455',
      'pixel456',
      'pixel457',
      'pixel458',
      'pixel459',
      'pixel460',
      'pixel461',
      'pixel462',
      'pixel463',
      'pixel464',
      'pixel465',
      'pixel466',
      'pixel467',
      'pixel468',
      'pixel469',
      'pixel470',
      'pixel471',
      'pixel472',
      'pixel473',
      'pixel474',
      'pixel475',
      'pixel476',
      'pixel477',
      'pixel478',
      'pixel479',
      'pixel480',
      'pixel481',
      'pixel482',
      'pixel483',
      'pixel484',
      'pixel485',
      'pixel486',
      'pixel487',
      'pixel488',
      'pixel489',
      'pixel490',
      'pixel491',
      'pixel492',
      'pixel493',
      'pixel494',
      'pixel495',
      'pixel496',
      'pixel497',
      'pixel498',
      'pixel499',
      'pixel500',
      'pixel501',
      'pixel502',
      'pixel503',
      'pixel504',
      'pixel505',
      'pixel506',
      'pixel507',
      'pixel508',
      'pixel509',
      'pixel510',
      'pixel511',
      'pixel512',
      'pixel513',
      'pixel514',
      'pixel515',
      'pixel516',
      'pixel517',
      'pixel518',
      'pixel519',
      'pixel520',
      'pixel521',
      'pixel522',
      'pixel523',
      'pixel524',
      'pixel525',
      'pixel526',
      'pixel527',
      'pixel528',
      'pixel529',
      'pixel530',
      'pixel531',
      'pixel532',
      'pixel533',
      'pixel534',
      'pixel535',
      'pixel536',
      'pixel537',
      'pixel538',
      'pixel539',
      'pixel540',
      'pixel541',
      'pixel542',
      'pixel543',
      'pixel544',
      'pixel545',
      'pixel546',
      'pixel547',
      'pixel548',
      'pixel549',
      'pixel550',
      'pixel551',
      'pixel552',
      'pixel553',
      'pixel554',
      'pixel555',
      'pixel556',
      'pixel557',
      'pixel558',
      'pixel559',
      'pixel560',
      'pixel561',
      'pixel562',
      'pixel563',
      'pixel564',
      'pixel565',
      'pixel566',
      'pixel567',
      'pixel568',
      'pixel569',
      'pixel570',
      'pixel571',
      'pixel572',
      'pixel573',
      'pixel574',
      'pixel575',
      'pixel576',
      'pixel577',
      'pixel578',
      'pixel579',
      'pixel580',
      'pixel581',
      'pixel582',
      'pixel583',
      'pixel584',
      'pixel585',
      'pixel586',
      'pixel587',
      'pixel588',
      'pixel589',
      'pixel590',
      'pixel591',
      'pixel592',
      'pixel593',
      'pixel594',
      'pixel595',
      'pixel596',
      'pixel597',
      'pixel598',
      'pixel599',
      'pixel600',
      'pixel601',
      'pixel602',
      'pixel603',
      'pixel604',
      'pixel605',
      'pixel606',
      'pixel607',
      'pixel608',
      'pixel609',
      'pixel610',
      'pixel611',
      'pixel612',
      'pixel613',
      'pixel614',
      'pixel615',
      'pixel616',
      'pixel617',
      'pixel618',
      'pixel619',
      'pixel620',
      'pixel621',
      'pixel622',
      'pixel623',
      'pixel624',
      'pixel625',
      'pixel626',
      'pixel627',
      'pixel628',
      'pixel629',
      'pixel630',
      'pixel631',
      'pixel632',
      'pixel633',
      'pixel634',
      'pixel635',
      'pixel636',
      'pixel637',
      'pixel638',
      'pixel639',
      'pixel640',
      'pixel641',
      'pixel642',
      'pixel643',
      'pixel644',
      'pixel645',
      'pixel646',
      'pixel647',
      'pixel648',
      'pixel649',
      'pixel650',
      'pixel651',
      'pixel652',
      'pixel653',
      'pixel654',
      'pixel655',
      'pixel656',
      'pixel657',
      'pixel658',
      'pixel659',
      'pixel660',
      'pixel661',
      'pixel662',
      'pixel663',
      'pixel664',
      'pixel665',
      'pixel666',
      'pixel667',
      'pixel668',
      'pixel669',
      'pixel670',
      'pixel671',
      'pixel672',
      'pixel673',
      'pixel674',
      'pixel675',
      'pixel676',
      'pixel677',
      'pixel678',
      'pixel679',
      'pixel680',
      'pixel681',
      'pixel682',
      'pixel683',
      'pixel684',
      'pixel685',
      'pixel686',
      'pixel687',
      'pixel688',
      'pixel689',
      'pixel690',
      'pixel691',
      'pixel692',
      'pixel693',
      'pixel694',
      'pixel695',
      'pixel696',
      'pixel697',
      'pixel698',
      'pixel699',
      'pixel700',
      'pixel701',
      'pixel702',
      'pixel703',
      'pixel704',
      'pixel705',
      'pixel706',
      'pixel707',
      'pixel708',
      'pixel709',
      'pixel710',
      'pixel711',
      'pixel712',
      'pixel713',
      'pixel714',
      'pixel715',
      'pixel716',
      'pixel717',
      'pixel718',
      'pixel719',
      'pixel720',
      'pixel721',
      'pixel722',
      'pixel723',
      'pixel724',
      'pixel725',
      'pixel726',
      'pixel727',
      'pixel728',
      'pixel729',
      'pixel730',
      'pixel731',
      'pixel732',
      'pixel733',
      'pixel734',
      'pixel735',
      'pixel736',
      'pixel737',
      'pixel738',
      'pixel739',
      'pixel740',
      'pixel741',
      'pixel742',
      'pixel743',
      'pixel744',
      'pixel745',
      'pixel746',
      'pixel747',
      'pixel748',
      'pixel749',
      'pixel750',
      'pixel751',
      'pixel752',
      'pixel753',
      'pixel754',
      'pixel755',
      'pixel756',
      'pixel757',
      'pixel758',
      'pixel759',
      'pixel760',
      'pixel761',
      'pixel762',
      'pixel763',
      'pixel764',
      'pixel765',
      'pixel766',
      'pixel767',
      'pixel768',
      'pixel769',
      'pixel770',
      'pixel771',
      'pixel772',
      'pixel773',
      'pixel774',
      'pixel775',
      'pixel776',
      'pixel777',
      'pixel778',
      'pixel779',
      'pixel780',
      'pixel781',
      'pixel782',
      'pixel783',
      'pixel784'],
     'target_names': ['class'],
     'DESCR': "**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \n**Please cite**:  \n\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \n\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \n\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \n\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\n\nDownloaded from openml.org.",
     'details': {'id': '554',
      'name': 'mnist_784',
      'version': '1',
      'description_version': '1',
      'format': 'ARFF',
      'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'],
      'upload_date': '2014-09-29T03:28:38',
      'language': 'English',
      'licence': 'Public',
      'url': 'https://www.openml.org/data/v1/download/52667/mnist_784.arff',
      'file_id': '52667',
      'default_target_attribute': 'class',
      'tag': ['AzurePilot',
       'OpenML-CC18',
       'OpenML100',
       'study_1',
       'study_123',
       'study_41',
       'study_99',
       'vision'],
      'visibility': 'public',
      'minio_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',
      'status': 'active',
      'processing_date': '2020-11-20 20:12:09',
      'md5_checksum': '0298d579eb1b86163de7723944c7e495'},
     'url': 'https://www.openml.org/d/554'}




```python
X, y = mnist["data"], mnist["target"]
X = np.array(X)
y = y.astype(np.int8)

print(X.shape, y.shape)
```

    (70000, 784) (70000,)



```python
import numpy as np
```


```python
if i <= 3 or i >= 17 for i in range(20)
```


      File "<ipython-input-3-706de7375c54>", line 1
        if i <= 3 or i >= 17 for i in range(20)
                             ^
    SyntaxError: invalid syntax




```python
mystr = 'life is too short'
print(mystr[::-1])
```

    trohs oot si efil



```python
test = [['ghd',11], ['ds',12, 3], ['afa',42]]
print(len(test))
test[-2][1:-1]
```

    3





    [12]




```python
def ma(x):
    return x*2
result = map(ma, [1,2,3,4])
print(list(result))
```

    [2, 4, 6, 8]



```python
%matplotlib inline
import matplotlib
import matplotlib.pyplot as plt

some_digit = X[36000]
some_digit_image = some_digit.reshape(28, 28)

plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,
           interpolation="nearest")
plt.axis("off")
plt.show()
```


![png](output_8_0.png)



```python
y[36000]
```




    9




```python
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```


```python
import numpy as np

shuffle_index = np.random.permutation(60000)
X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]
```

### 3.2 이진 분류기 훈련


```python
y_train_5 = (y_train == 5)
y_test_5 = (y_test == 5)
```


```python
X_train
```




    array([[0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           ...,
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.]])




```python
y_train_5
```




    56599    False
    43647    False
    29253     True
    27738    False
    12706    False
             ...  
    2322     False
    39534    False
    14990    False
    39623    False
    11090    False
    Name: class, Length: 60000, dtype: bool




```python
from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(max_iter=5, random_state=42)
sgd_clf.fit(X_train, y_train_5)
```

    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "





    SGDClassifier(max_iter=5, random_state=42)




```python
sgd_clf.predict([some_digit])
```




    array([False])



SGDClassifier는 이진 선형 분류기로

- 계산값을 기반으로 계산값이 0보다 작으면 -1, 0보다 크면 1로 분류한다.
- 이진 선형 분류기는 선, 평면, 초평면을 이용해 2개의 클래스를 구분하는 분류기이다.

### 3.3 성능 측정

### 3.3.1 교차 검증을 사용한 정확도 측정


```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone

skfolds = StratifiedKFold(n_splits=3, random_state=42)

for train_index, test_index in skfolds.split(X_train, y_train_5):
    clone_clf = clone(sgd_clf)
    X_train_folds = X_train[train_index]
    y_train_folds = y_train_5[train_index]
    X_test_fold = X_train[test_index]
    y_test_fold = y_train_5[test_index]
    
    clone_clf.fit(X_train_folds, y_train_folds)
    y_pred = clone_clf.predict(X_test_fold)
    n_correct = sum(y_pred == y_test_fold)
    print(n_correct / len(y_pred))
```

위 코드는 사이킷런의 cross_val_score() 함수와 거의 같은 작업을 수행하고 동일한 결과를 출력합니다.

StratifiedKFold는 클래스별 비율이 유지되도록 폴드를 만들기 위해 계층적 샘플링을 수행합니다.


```python
from sklearn.model_selection import cross_val_score
cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```

    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "
    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "
    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "





    array([0.95735, 0.96135, 0.9695 ])



정확도가 95%이상으로 매우 높게 나타났다.


```python
from sklearn.base import BaseEstimator

class Never5Classifier(BaseEstimator):
    def fit(self, X, y=None):
        pass
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)
```


```python
never_5_clf = Never5Classifier()
cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```




    array([0.90955, 0.9097 , 0.9097 ])



5-감지기는 5가 아님 을 예측할 확률이 90% 이상으로 측정되었다.

이는 정확도를 분류기의 성능 측정 지표로 선호하지 않는 이유를 보여준다.
특히, 불균형 데이터셋을 다룰때 (어떤 클래스가 다른 것보다 월등히 많은 경우) 더욱 그렇다.

### 3.3.2 오차 행렬

분류기의 성능을 평가하는 더 좋은 방법은 오차 행렬(confusion matrix)를 조사하는 것이다.


```python
from sklearn.model_selection import cross_val_predict

y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
```

    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "
    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "
    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "



```python
y_train_pred.shape
```




    (60000,)



cross_val_predict는 cross_val_score와 마찬가지로 K-겹 교차 검증을 수행하지만 평가 점수를 반환하지 않고 각 테스트 폴드에서 얻은 예측을 반환한다.


```python
from sklearn.metrics import confusion_matrix
confusion_matrix(y_train_5, y_train_pred)
```




    array([[53826,   753],
           [ 1483,  3938]])



행 = 실제 클래스, 열 = 예측 클래스

||예측P|예측N|
|--|--|--|
|실제P|TP|FN|
|실제N|FP|TN|

$$Precision = \frac{TP}{TP + FP}$$
$$Recall = \frac{TP}{TP + FN}$$

### 3.3.3 정밀도와 재현율


```python
from sklearn.metrics import precision_score, recall_score

print(precision_score(y_train_5, y_train_pred))
print(recall_score(y_train_5, y_train_pred))
```

    0.839479855041569
    0.7264342372256042


앞서 90%가 넘었던 정확도와 비교해서 수치가 비교적 낮은 것으로 보인다.


```python
from sklearn.metrics import f1_score

f1_score(y_train_5, y_train_pred)
```




    0.778876582278481



정밀도와 재현율을 F1점수로 변형하여 사용하면 편리한 경우가 많다. 정밀도와 재현율이 비슷한 분류기에서 F1점수가 높다. 하지만 항상 이게 바람직한 것은 아니다. 상황에 따라 정밀도나 재현율 중 하나가 더 중요한 경우가 있다.

ex)
- 정밀도 : 안전한 동영상 분류기, 좋은 영상을 많이 제외하더라도(낮은 재현율) 안전한 것들만 노출시킴(높은 정밀도)
- 재현율 : 감시 카메라 분류기, 경비원이 잘못된 호출을 받더라도(낮은 정밀도) 거의 모든 종도둑을 잡아냄(높은 재현율)

### 3.3.4 정밀도/재현율 트레이드오프


```python
y_scores = sgd_clf.decision_function([some_digit])
y_scores
```




    array([-350314.71344674])



* decision_function : 결정 함수, 임계값을 기준으로 양성 클래스나 음성 클래스에 속한다고 믿는 정도

ex) 4.23xx = 양성, -1.62xx = 음성 (임곗값이 0일때)

사이킷런에서 임계값을 직접 지정할 수는 없음


```python
threshold = -400000
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred
```




    array([ True])




```python
threshold = 0
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred
```




    array([False])




```python
y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,
                            method="decision_function")
```

    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "
    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "
    /Users/yoonsung/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
      warnings.warn("Maximum number of iteration reached before "



```python
y_train_5.shape
```




    (60000,)




```python
y_scores.shape
```




    (60000,)




```python
from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)
```


```python
precisions, recalls, thresholds
```




    (array([0.0910251 , 0.09100984, 0.09101137, ..., 1.        , 1.        ,
            1.        ]),
     array([1.00000000e+00, 9.99815532e-01, 9.99815532e-01, ...,
            3.68935621e-04, 1.84467810e-04, 0.00000000e+00]),
     array([-1556658.84904734, -1556398.74825082, -1555751.82960944, ...,
              918123.95020997,   939691.87906567,  1108104.14911643]))




```python
# 항상 분석 전 디폴트 라이브러리 임포트

import pandas as pd
import numpy as np
import seaborn as sns
from IPython.display import set_matplotlib_formats
import matplotlib
import warnings
warnings.filterwarnings(action="ignore")

matplotlib.rc('font', family='AppleGothic')
set_matplotlib_formats('retina')
matplotlib.rc('axes', unicode_minus=False)

pd.options.display.max_rows=100
pd.options.display.max_columns=100
pd.set_option('display.float_format', '{:.2f}'.format)
```


```python
def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):
    plt.plot(thresholds, precisions[:-1], "b--", label="정밀도")
    plt.plot(thresholds, recalls[:-1], "g-", label="재현율")
    plt.ticklabel_format(style='plain') # scientific notation 제거
    plt.xlabel("임곗값")
    plt.legend(loc="center left")
    plt.ylim([0, 1])

plt.figure(figsize=(12,4)) # 그래프 크기 변경
plot_precision_recall_vs_threshold(precisions, recalls, thresholds)
plt.show()
```


![png](output_51_0.png)


임계값이 높아질수록 재현율은 낮아지고, 정밀도는 높아짐을 알 수 있다.

정밀도 곡선이 재현율 곡선보다 더 울퉁불퉁한 이유는 임곗값을 올리더라도 정밀도가 가끔 낮아질 때가 있기 때문이다.(일반적으로는 높아져야 함)

이제 작업에 맞는 최선의 정밀도/재현율 트레이드오프를 만드는 임곗값을 선택하면 된다.

재현율에 대한 정밀도 곡선을 그리면 좋은 정밀도/재현율 트레이드오프를 선택하는 데 도움이 된다.


```python
plt.plot(recalls, precisions)
plt.xlabel("재현율")
plt.ylabel("정밀도")
plt.show()
```


![png](output_53_0.png)


재현율 80% 근처에서 정밀도가 급격하게 줄어들기 시작한다. 이 하강점 직전을 정밀도/재현율 트레이드오프를 선택하는 것이 좋다. 예를 들면 재현율이 60% 정도인 지점입니다. 프로젝트에 따라 달라질 수 있습니다.


```python
def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):
    plt.plot(thresholds, precisions[:-1], "b--", label="정밀도")
    plt.plot(thresholds, recalls[:-1], "g-", label="재현율")
    plt.ticklabel_format(style='plain') # scientific notation 제거
    plt.xlabel("임곗값")
    plt.legend(loc="center left")
    plt.grid()
    plt.xlim([-100000,100000])
    plt.ylim([0, 1])

plt.figure(figsize=(12,4)) # 그래프 크기 변경
plot_precision_recall_vs_threshold(precisions, recalls, thresholds)
plt.show()
```


![png](output_55_0.png)


정밀도 90%를 달성하는 것이 목표라고 가정하면, 그래프에서 임곗값이 약 50,000정도라는 것을 알 수 있습니다.(확대해서 살펴보기) 훈련 세트에 대한 예측을 만들려면 분류기의 predict() 메서드를 호출하는 대신 다음 코드를 실행하면 됩니다.


```python
y_train_pred_90 = (y_scores > 50000)
print(precision_score(y_train_5, y_train_pred_90))
print(recall_score(y_train_5, y_train_pred_90))
```

    0.8949935815147625
    0.643054786939679


정밀도 90%를 달성한 분류기를 만들었다. 가상의 정밀도에 대해서도 분류기를 쉽게 만들 수 있음을 알 수 있다. 충분히 큰 임곗값을 지정하면 끝이다. 하지만 재현율이 너무 낮다면 높은 정밀도의 분류기는 전혀 유용하지 않다! '99% 정밀도를 달성하자'라고 하면 '재현율은 얼마?'라고 반드시 물어야한다.

### 3.3.5 ROC곡선

수신지 조작 특성 (Receiver Operating Characteristic = ROC) 곡선도 이진 분류에서 널리 사용되는 도구다.

ROC 곡선은 거짓 양성 비율(false positive rate = FRP) 에 대한 진짜 양성 비율(true positive rate = TPR) 의 곡선이다.

ROC 곡선은 민감도(재현율)에 대한 1-특이도(specificity) 그래프이다.
$$Specificity = \frac{TN}{FP + TN}$$


```python
from sklearn.metrics import roc_curve

fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)
```


```python
def plot_roc_curve(fpr, tpr, label=None):
    plt.plot(fpr, tpr, linewidth=2, label=label)
    plt.plot([0,1], [0,1], 'k--')
    plt.axis([0,1,0,1])
    plt.xlabel('거짓 양성 비율(FPR)')
    plt.ylabel('진짜 양성 비율(TPR)')
    
plot_roc_curve(fpr, tpr)
plt.show()
```


![png](output_62_0.png)


좋은 분류기는 점선으로부터 최대한 멀리 떨어져 있어야 한다.

즉, 곡선 아래의 면적(area under the curve = AUC)가 커야 한다.

완벽한 분류기는 AUC=1이고, 완전한 랜덤 분류기는 AUC=0.5이다.


```python
from sklearn.metrics import roc_auc_score
roc_auc_score(y_train_5, y_scores)
```




    0.9613528226165627



ROC곡선과 PR(정밀도/재현율) 곡선 중 어느 것을 사용해야 할까.

일반적인 법칙은 양성 클래스(P)가 드물거나 거짓 음성(FN)보다 거짓 양성(FP)이 더 중요할 때 PR곡선을 사용하고 그렇지 않으면 ROC 곡선을 사용합니다.


```python
from sklearn.ensemble import RandomForestClassifier

forest_clf = RandomForestClassifier(random_state=42)
y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,
                                   method="predict_proba")
```

RandomForestClassifier에는 decision_function()메서드가 없고, 대신 predict_proba()메서드가 있다. 사이킷런 분류기는 일반적으로 두 메서드 중 하나 또는 둘 모두를 가지고 있다.

predict_proba() 메서드는 샘플이 행, 클래스가 열이고 샘플이 주어진 클래스에 속할 확률을 담은 배열을 반환한다.


```python
y_scores_forest = y_probas_forest[:,1]
fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)
```


```python
plt.plot(fpr, tpr, "b:", label="SGD")
plot_roc_curve(fpr_forest, tpr_forest, "랜덤 포레스트")
plt.legend(loc="lower right")
plt.show()
```


![png](output_69_0.png)


두 모델을 비교해보면, SGD보다 랜덤 포레스트가 왼쪽 모서리에 더 가까운 것을 알 수 있다.

이진 분류기를 훈련시키는 방법, 작업에 맞는 적절한 지표 선택, 교차 검증을 사용한 평가, 요구사항에 맞는 정밀도/재현율 트레이드오프 선택, ROC곡선과 ROC AUC 점수를 사용한 여러 모델의 비교에 대해 알아 보았다.

### 3.4 다중 분류

- 다중 분류기(다항 분류기) 가능 = 랜덤 포레스트 나이브 베이즈 등
- 이진 분류기만 가능 = 서포트 벡터 머신, 선형 분류기
- 일대다(one-versus-all, one-versus-the-rest = OvA) 전략 과 일대일(one-versus-one = OvO)전략을 통해 이진 분류기 여러개로 다중 분류를 진행할 수도 있다.

SVM은 OvO를 적용하고, 선형 분류기는 OvA를 선택하기도 한다. (SVM은 훈련 세트의 크기에 민감하기 때문)


```python
sgd_clf.fit(X_train, y_train)
sgd_clf.predict([some_digit])
```




    array([9], dtype=int8)




```python
some_digit_scores = sgd_clf.decision_function([some_digit])
some_digit_scores
```




    array([[-894708.63621989, -382941.76620019, -756667.45791241,
            -206606.13368067, -131482.02582012, -149361.71405397,
            -731885.19809315, -222861.12764607, -458085.56809839,
            -129649.65902425]])



내부에서는 사이킷런이 실제로 10개의 이진 분류기를 훈련시키고 각각의 결정 점수를 얻어 점수가 가장 높은 클래스를 선택합니다.


```python
np.argmax(some_digit_scores)
```




    9




```python
sgd_clf.classes_
```




    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int8)




```python
sgd_clf.classes_[9]
```




    9



분류기가 훈련될 때 classes_속성에 타깃 클래스의 리스트를 값으로 정렬하여 저장한다.


```python
from sklearn.multiclass import OneVsOneClassifier
ovo_clf = OneVsOneClassifier(SGDClassifier(max_iter=5, random_state=42))
ovo_clf.fit(X_train, y_train)
ovo_clf.predict([some_digit])
```




    array([9], dtype=int8)



OvO를 이용하여 선형분류기를 활용해 다중 분류를 하는 코드는 위와 같다.


```python
len(ovo_clf.estimators_)
```




    45




```python
forest_clf.fit(X_train, y_train)
forest_clf.predict([some_digit])
```




    array([9], dtype=int8)



랜덤포레스트를 이용하여 다중분류를 진행한다. 랜덤포레스트는 직접 샘플을 다중 클래스로 분류할 수 있다.


```python
forest_clf.predict_proba([some_digit])
```




    array([[0.  , 0.01, 0.  , 0.  , 0.09, 0.  , 0.01, 0.03, 0.01, 0.85]])




```python
cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring="accuracy")
```




    array([0.84985, 0.8536 , 0.87715])



랜덤 분류기를 통해 84%의 정확도를 얻었지만, 성능을 더 높일 여지가 있다. 간단하게 스케일을 조정하여 정확도를 90%이상으로 높일 수 있다.


```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))
cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring="accuracy")
```




    array([0.90965, 0.9103 , 0.91275])



### 3.5 에러 분석

실제 프로젝트라면 다음의 단계를 따를 것이다.
1. 데이터 준비 단계에서 가능한 선택사항을 탐색하고,
2. 여러 모델을 시도하고,
3. 가장 좋은 몇 개를 골라 GridSearchCV를 사용해 하이퍼파라미터를 세밀하고 튜닝하고,
4. 가능한 pipeline으로 연결하여 자동화한다.

그리고 가능성이 높은 모델을 하나 찾았다고 가정하고 이 모델의 성능을 향상시킬 방법을 찾아보도록 하자.

한 가지 방법은 만들어진 에러의 종류를 분석하는 것입니다.


```python
y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)
conf_mx = confusion_matrix(y_train, y_train_pred)
conf_mx
```




    array([[5738,    3,   22,    9,   10,   48,   38,   10,   42,    3],
           [   2, 6454,   52,   24,    6,   43,    6,    8,  134,   13],
           [  60,   35, 5335,   92,   84,   25,   87,   57,  167,   16],
           [  52,   43,  144, 5313,    2,  248,   31,   59,  147,   92],
           [  19,   25,   35,    7, 5398,    6,   52,   25,   72,  203],
           [  68,   39,   37,  172,   78, 4650,   94,   31,  162,   90],
           [  36,   23,   46,    2,   45,   95, 5619,    5,   46,    1],
           [  25,   19,   71,   24,   53,   11,    4, 5823,   18,  217],
           [  47,  151,   69,  136,   15,  168,   51,   26, 5053,  135],
           [  42,   35,   22,   84,  158,   37,    2,  213,   85, 5271]])




```python
plt.matshow(conf_mx, cmap=plt.cm.gray)
plt.show()
```


![png](output_93_0.png)



```python
row_sums = conf_mx.sum(axis=1, keepdims=True)
norm_conf_mx = conf_mx / row_sums
```


```python
np.fill_diagonal(norm_conf_mx, 0)
plt.matshow(norm_conf_mx, cmap=plt.cm.gray)
plt.show()
```


![png](output_95_0.png)


행 = 실제 클래스 / 열 = 예측 클래스

밝은 부분일 수록 값이 큰 것을 의미하며, 밝을수록 다른 숫자와 혼동이 되었다는 것을 의미한다.

위 그래프를 바탕으로 보면, 3과 5가 서로 혼돈되는 것을 보완하고, 8과 9를 더 잘 분류할 수 있도록 개선할 필요가 보인다.

예를 들어, 이 숫자들에 대한 훈련 데이터를 더 모을 수 있다. 또는 분류기에 도움 될 만한 특성을 더 찾아볼 수 있습니다. 예를 들어 동심원의 수를 세는 알고리즘 같은 것(8은 두 개, 6은 하나, 5는 0개) 또는 동심원 같은 어떤 패턴이 드러나도록 (Scikit-image, Pillow, OpenCV 등을 사용해서)이미지를 전처리 해볼 수 있습니다.


```python
def plot_digits(instances, images_per_row=10, **options):
    size = 28
    images_per_row = min(len(instances), images_per_row)
    images = [instance.reshape(size,size) for instance in instances]
    n_rows = (len(instances) - 1) // images_per_row + 1
    row_images = []
    n_empty = n_rows * images_per_row - len(instances)
    images.append(np.zeros((size, size * n_empty)))
    for row in range(n_rows):
        rimages = images[row * images_per_row : (row + 1) * images_per_row]
        row_images.append(np.concatenate(rimages, axis=1))
    image = np.concatenate(row_images, axis=0)
    plt.imshow(image, cmap = matplotlib.cm.binary, **options)
    plt.axis("off")
```


```python
cl_a, cl_b = 3, 5
X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]
X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]
X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]
X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]

plt.figure(figsize=(8,8))
plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)
plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)
plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)
plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)
plt.show()
```


![png](output_98_0.png)


### 3.6 다중 레이블 분류

Multilabel classificaition

얼굴 인식 분류기와 같이 같은 사진에 여러 사람이 등장하는 경우에 각각의 사람들(다중 레이블)을 분류해줘야한다.


```python
from sklearn.neighbors import KNeighborsClassifier

y_train_large = (y_train >= 7)
y_train_odd = (y_train % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]

knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)
```




    KNeighborsClassifier()



KNeighborsClassifier, 결정 트리, 랜덤 포레스트, OneVsRestClassifier에서 다중 레이블 분류를 지원한다.


```python
knn_clf.predict([some_digit])
```




    array([[ True,  True]])



숫자 9는 7보다 큰 수이면서, 홀수 이기에 True, True 결과가 나왔다.


```python
y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3, n_jobs=-1)
f1_score(y_multilabel, y_train_knn_pred, average='macro')
```




    0.9769130570549585



다중 레이블 분류기를 평가하는 방법은 많다. 적절한 지표는 프로젝트에 따라 다르다. 예를 들어 각 레이블의 F1 를 구하고 (또는 앞서 언급한 어떤 이진 분류 지표를 사용하여) 간단하게 평균 점수를 계산한다. 위 코드는 모든 레이블에 대한 F1점수의 평균을 계산한다.

실제로는 아닐 수 있지만 이 코드는 모든 레이블의 가중치가 같다고 가정한 것이다. 특히 앨리스 사진이 밥이나 찰리 사진보다 훨씬 많다면 앨리스 사진에 대한 분류기의 점수에 더 높은 가중치를 둘 것이다. 간단한 방법을 레이블에 클래스의 지지도(support)(즉, 타깃 레이블에 속한 샘플 수)를 가중치로 주는 것이다. 이렇게 하려면 위 코드에서 average='weighted'로 설정하면 된다.

### 3.7 다중 출력 분류

다중 출력 다중 클래스 분류(multioutput-multiclass classfication = 다중 출력 분류 multioutput classfication)은 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화한 것이다.(즉, 값을 두 개 이상 가질 수 있다.)

ex) 이미지에서 노이즈를 제거하는 시스템


```python
# noise = np.random.randint(0, 100, (len(X_train), 784))
# X_train_mod = X_train + noise
# noise = np.random.randint(0, 100, (len(X_test), 784))
# X_test_mod = X_test + noise
# y_train_mod = X_train
# y_test_mod = X_test
```


```python
# knn_clf.fit(X_train_mod, y_train_mod)
# clean_digit = knn.clf.predict([X_test_mod[some_index]])
# plot_digit(clean_digit)
```

### 3.8 연습문제


```python

```
